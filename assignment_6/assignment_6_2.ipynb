{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dhanush-adk/machine_learning/blob/main/assignment_6/assignment_6_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEdC6LDkQ4XS",
        "outputId": "cac9aef1-db75-4c08-ed98-021125e1ae09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 12.3 s (started: 2023-12-02 01:00:56 +00:00)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchvision import datasets, transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXlQeX-1R-ia",
        "outputId": "0070b864-7380-440d-ac10-aa13253a9c94"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7b66967524f0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 5.73 ms (started: 2023-12-02 01:01:08 +00:00)\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsiQp8c3Ux_Q",
        "outputId": "a8c726f0-e4bb-4d99-9547-1734c569f7ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 75240061.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "time: 18.5 s (started: 2023-12-02 01:01:08 +00:00)\n"
          ]
        }
      ],
      "source": [
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "# Calculate mean and std\n",
        "imgs = torch.stack([img_t for img_t, _ in train_dataset], dim=3)\n",
        "mean = imgs.view(3, -1).mean(dim=1)\n",
        "std = imgs.view(3, -1).std(dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jooydkvUVt8n",
        "outputId": "2c98bb4b-247c-4815-c805-a9aa19680a66"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4914, 0.4822, 0.4465])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 31 ms (started: 2023-12-02 01:01:26 +00:00)\n"
          ]
        }
      ],
      "source": [
        "mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XC98Saf9VuvN",
        "outputId": "0164c2ed-6463-4912-81ca-b2fe79eb1d8e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2470, 0.2435, 0.2616])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 4.08 ms (started: 2023-12-02 01:01:26 +00:00)\n"
          ]
        }
      ],
      "source": [
        "std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJjBdJ1VU-TY",
        "outputId": "608ac20a-dc23-46e6-9038-9eb800a47cb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 60.8 ms (started: 2023-12-02 01:01:26 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIRtCChAV2nr",
        "outputId": "902f5447-df8e-43e1-b981-54d1c9703341"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.06 ms (started: 2023-12-02 01:01:26 +00:00)\n"
          ]
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aItV66gmV1zl",
        "outputId": "671704bf-40b1-4834-8a28-ee18b7019e34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 570 µs (started: 2023-12-02 01:01:26 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Define transformation with calculated mean and std\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7LgQLimUXl2",
        "outputId": "f3698817-0c95-4758-a8b7-bb554111e0d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 492 ms (started: 2023-12-02 01:01:26 +00:00)\n"
          ]
        }
      ],
      "source": [
        "cifar10 = datasets.CIFAR10(\n",
        "    './data', train=True, download=False,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXge3KZ0Ud2I",
        "outputId": "8d13921c-ffd6-461e-9882-7af75984d37b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 352 ms (started: 2023-12-02 01:01:27 +00:00)\n"
          ]
        }
      ],
      "source": [
        "cifar10_val = datasets.CIFAR10(\n",
        "     './data', train=False, download=False,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zGrIQDbdE0r",
        "outputId": "914f13fb-2ace-4690-9d4e-e1605f2fbf33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 32, 32])\n",
            "time: 11.4 ms (started: 2023-12-02 01:01:27 +00:00)\n"
          ]
        }
      ],
      "source": [
        "first_image, label = cifar10[0]\n",
        "print(first_image.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnSjAIclhyxH",
        "outputId": "bbf5b3b7-758a-4d03-da80-97cc0f13f47f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 544 µs (started: 2023-12-02 01:01:27 +00:00)\n"
          ]
        }
      ],
      "source": [
        "train_loader = DataLoader(cifar10, batch_size=32, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(cifar10_val, batch_size=32, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1oMEPlOWeyJ",
        "outputId": "da0d57ed-f594-4cf1-c506-229dee4949fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 5.25 s (started: 2023-12-01 22:06:23 +00:00)\n"
          ]
        }
      ],
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(32 * 32 * 3, 512),\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(512, 10)\n",
        ").to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICZu-ov1cO7y",
        "outputId": "386b27d3-2227-47bb-889e-4ca9d9bf211d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.6 ms (started: 2023-12-02 01:01:27 +00:00)\n"
          ]
        }
      ],
      "source": [
        "def train_model(model, train_loader, test_loader, num_epochs=300, lr=0.001):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Testing the model\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        all_predicted = []\n",
        "        all_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in test_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "                all_predicted.extend(predicted.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        accuracy = correct / total\n",
        "\n",
        "        if epoch % 1 == 0:\n",
        "            print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}, Test Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "    # Classification Report\n",
        "    report = classification_report(all_labels, all_predicted)\n",
        "    print(\"Classification Report:\\n\", report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e5OZzeNhGqi",
        "outputId": "8b8bffa2-0146-4f4d-c744-ea55f9ab31e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300, Loss: 1.7398397800484606, Test Accuracy: 41.89%\n",
            "Epoch 2/300, Loss: 1.634406721675846, Test Accuracy: 43.21%\n",
            "Epoch 3/300, Loss: 1.5660125428258953, Test Accuracy: 45.81%\n",
            "Epoch 4/300, Loss: 1.5045548411645115, Test Accuracy: 45.98%\n",
            "Epoch 5/300, Loss: 1.4462770357089247, Test Accuracy: 46.90%\n",
            "Epoch 6/300, Loss: 1.393377955266473, Test Accuracy: 47.19%\n",
            "Epoch 7/300, Loss: 1.33971855736511, Test Accuracy: 46.97%\n",
            "Epoch 8/300, Loss: 1.286995179517408, Test Accuracy: 47.02%\n",
            "Epoch 9/300, Loss: 1.2365475362184637, Test Accuracy: 47.75%\n",
            "Epoch 10/300, Loss: 1.1836568696027525, Test Accuracy: 48.50%\n",
            "Epoch 11/300, Loss: 1.1335558970616708, Test Accuracy: 48.34%\n",
            "Epoch 12/300, Loss: 1.0809114643265938, Test Accuracy: 48.87%\n",
            "Epoch 13/300, Loss: 1.029821600467062, Test Accuracy: 47.75%\n",
            "Epoch 14/300, Loss: 0.9790819698774273, Test Accuracy: 48.79%\n",
            "Epoch 15/300, Loss: 0.9285842062224964, Test Accuracy: 47.34%\n",
            "Epoch 16/300, Loss: 0.8829675394986886, Test Accuracy: 46.96%\n",
            "Epoch 17/300, Loss: 0.8342071225341131, Test Accuracy: 47.62%\n",
            "Epoch 18/300, Loss: 0.7866293871852731, Test Accuracy: 47.83%\n",
            "Epoch 19/300, Loss: 0.7429452535820862, Test Accuracy: 46.97%\n",
            "Epoch 20/300, Loss: 0.6994615423892907, Test Accuracy: 47.29%\n",
            "Epoch 21/300, Loss: 0.6582873234250037, Test Accuracy: 47.12%\n",
            "Epoch 22/300, Loss: 0.6156003515421391, Test Accuracy: 46.59%\n",
            "Epoch 23/300, Loss: 0.576058319190032, Test Accuracy: 47.60%\n",
            "Epoch 24/300, Loss: 0.5407616428206231, Test Accuracy: 46.67%\n",
            "Epoch 25/300, Loss: 0.5076861263122302, Test Accuracy: 47.23%\n",
            "Epoch 26/300, Loss: 0.4707470684671585, Test Accuracy: 46.16%\n",
            "Epoch 27/300, Loss: 0.44034276058943855, Test Accuracy: 45.38%\n",
            "Epoch 28/300, Loss: 0.41059330893264545, Test Accuracy: 46.27%\n",
            "Epoch 29/300, Loss: 0.38243159379092684, Test Accuracy: 46.59%\n",
            "Epoch 30/300, Loss: 0.35291599211541036, Test Accuracy: 45.84%\n",
            "Epoch 31/300, Loss: 0.3289514998652122, Test Accuracy: 45.96%\n",
            "Epoch 32/300, Loss: 0.3074599751393458, Test Accuracy: 46.61%\n",
            "Epoch 33/300, Loss: 0.2830347623282797, Test Accuracy: 46.64%\n",
            "Epoch 34/300, Loss: 0.26218090246902853, Test Accuracy: 45.45%\n",
            "Epoch 35/300, Loss: 0.24230989192207883, Test Accuracy: 46.78%\n",
            "Epoch 36/300, Loss: 0.22173591471507773, Test Accuracy: 45.94%\n",
            "Epoch 37/300, Loss: 0.20716336343296812, Test Accuracy: 46.17%\n",
            "Epoch 38/300, Loss: 0.19081516282886782, Test Accuracy: 46.48%\n",
            "Epoch 39/300, Loss: 0.17715056288465428, Test Accuracy: 44.93%\n",
            "Epoch 40/300, Loss: 0.16391193526376918, Test Accuracy: 46.62%\n",
            "Epoch 41/300, Loss: 0.14942144049344655, Test Accuracy: 46.61%\n",
            "Epoch 42/300, Loss: 0.13989854885011396, Test Accuracy: 46.02%\n",
            "Epoch 43/300, Loss: 0.1304408330410738, Test Accuracy: 46.34%\n",
            "Epoch 44/300, Loss: 0.11800768332447445, Test Accuracy: 45.97%\n",
            "Epoch 45/300, Loss: 0.11279167318317422, Test Accuracy: 45.57%\n",
            "Epoch 46/300, Loss: 0.10118142898675347, Test Accuracy: 45.66%\n",
            "Epoch 47/300, Loss: 0.09466805634871173, Test Accuracy: 45.91%\n",
            "Epoch 48/300, Loss: 0.0892984937454597, Test Accuracy: 45.83%\n",
            "Epoch 49/300, Loss: 0.08218878695547047, Test Accuracy: 46.33%\n",
            "Epoch 50/300, Loss: 0.07644442150456282, Test Accuracy: 46.11%\n",
            "Epoch 51/300, Loss: 0.07192159039388463, Test Accuracy: 45.95%\n",
            "Epoch 52/300, Loss: 0.0668475516760151, Test Accuracy: 46.46%\n",
            "Epoch 53/300, Loss: 0.06279168648958702, Test Accuracy: 46.29%\n",
            "Epoch 54/300, Loss: 0.058618890116812324, Test Accuracy: 45.80%\n",
            "Epoch 55/300, Loss: 0.055183724996586754, Test Accuracy: 46.16%\n",
            "Epoch 56/300, Loss: 0.05113796172669528, Test Accuracy: 45.63%\n",
            "Epoch 57/300, Loss: 0.04905187973534535, Test Accuracy: 46.14%\n",
            "Epoch 58/300, Loss: 0.046791759963723534, Test Accuracy: 46.23%\n",
            "Epoch 59/300, Loss: 0.043864647502714786, Test Accuracy: 46.06%\n",
            "Epoch 60/300, Loss: 0.04174053937706784, Test Accuracy: 46.32%\n",
            "Epoch 61/300, Loss: 0.039341191309536984, Test Accuracy: 46.03%\n",
            "Epoch 62/300, Loss: 0.03715188138160714, Test Accuracy: 46.09%\n",
            "Epoch 63/300, Loss: 0.0358054870352273, Test Accuracy: 46.06%\n",
            "Epoch 64/300, Loss: 0.03437384671066254, Test Accuracy: 46.35%\n",
            "Epoch 65/300, Loss: 0.03303456248778681, Test Accuracy: 45.66%\n",
            "Epoch 66/300, Loss: 0.03215892369407858, Test Accuracy: 45.89%\n",
            "Epoch 67/300, Loss: 0.030470268156734592, Test Accuracy: 46.02%\n",
            "Epoch 68/300, Loss: 0.028826122596426147, Test Accuracy: 45.96%\n",
            "Epoch 69/300, Loss: 0.027324613823090045, Test Accuracy: 46.04%\n",
            "Epoch 70/300, Loss: 0.02664047237235388, Test Accuracy: 46.14%\n",
            "Epoch 71/300, Loss: 0.025808130694232687, Test Accuracy: 45.93%\n",
            "Epoch 72/300, Loss: 0.02507488561707167, Test Accuracy: 46.02%\n",
            "Epoch 73/300, Loss: 0.024339277089304712, Test Accuracy: 45.99%\n",
            "Epoch 74/300, Loss: 0.023460932827351455, Test Accuracy: 46.14%\n",
            "Epoch 75/300, Loss: 0.022617636319972045, Test Accuracy: 46.02%\n",
            "Epoch 76/300, Loss: 0.021767551315947174, Test Accuracy: 46.12%\n",
            "Epoch 77/300, Loss: 0.02133085502350914, Test Accuracy: 46.01%\n",
            "Epoch 78/300, Loss: 0.020415819055798225, Test Accuracy: 45.96%\n",
            "Epoch 79/300, Loss: 0.019788710524400153, Test Accuracy: 45.92%\n",
            "Epoch 80/300, Loss: 0.019675272075377132, Test Accuracy: 45.96%\n",
            "Epoch 81/300, Loss: 0.018747400350616058, Test Accuracy: 45.88%\n",
            "Epoch 82/300, Loss: 0.018541271687483492, Test Accuracy: 45.04%\n",
            "Epoch 83/300, Loss: 0.018239852037430955, Test Accuracy: 45.97%\n",
            "Epoch 84/300, Loss: 0.017389990109294862, Test Accuracy: 45.86%\n",
            "Epoch 85/300, Loss: 0.01693366625645959, Test Accuracy: 45.87%\n",
            "Epoch 86/300, Loss: 0.016532093232291406, Test Accuracy: 46.00%\n",
            "Epoch 87/300, Loss: 0.01613064377043713, Test Accuracy: 46.09%\n",
            "Epoch 88/300, Loss: 0.015746426199260748, Test Accuracy: 45.98%\n",
            "Epoch 89/300, Loss: 0.01570569513388269, Test Accuracy: 46.04%\n",
            "Epoch 90/300, Loss: 0.015223961950637882, Test Accuracy: 46.07%\n",
            "Epoch 91/300, Loss: 0.014909831890437134, Test Accuracy: 45.95%\n",
            "Epoch 92/300, Loss: 0.01451954095381874, Test Accuracy: 45.71%\n",
            "Epoch 93/300, Loss: 0.01414921117192152, Test Accuracy: 45.92%\n",
            "Epoch 94/300, Loss: 0.014054080586694538, Test Accuracy: 45.73%\n",
            "Epoch 95/300, Loss: 0.013670801470486384, Test Accuracy: 45.73%\n",
            "Epoch 96/300, Loss: 0.013459231574874865, Test Accuracy: 45.98%\n",
            "Epoch 97/300, Loss: 0.013084702224125675, Test Accuracy: 46.06%\n",
            "Epoch 98/300, Loss: 0.012957961286906145, Test Accuracy: 46.09%\n",
            "Epoch 99/300, Loss: 0.012580455352938946, Test Accuracy: 46.10%\n",
            "Epoch 100/300, Loss: 0.01235194606599246, Test Accuracy: 46.06%\n",
            "Epoch 101/300, Loss: 0.012134836762321258, Test Accuracy: 46.10%\n",
            "Epoch 102/300, Loss: 0.011929219552886006, Test Accuracy: 45.77%\n",
            "Epoch 103/300, Loss: 0.01181220701107337, Test Accuracy: 45.78%\n",
            "Epoch 104/300, Loss: 0.011532240568988517, Test Accuracy: 45.95%\n",
            "Epoch 105/300, Loss: 0.011325615407840628, Test Accuracy: 46.00%\n",
            "Epoch 106/300, Loss: 0.011255013338461165, Test Accuracy: 46.08%\n",
            "Epoch 107/300, Loss: 0.011015685950003693, Test Accuracy: 45.94%\n",
            "Epoch 108/300, Loss: 0.010789697439548628, Test Accuracy: 45.81%\n",
            "Epoch 109/300, Loss: 0.010628545356191033, Test Accuracy: 45.88%\n",
            "Epoch 110/300, Loss: 0.010409894632324529, Test Accuracy: 45.94%\n",
            "Epoch 111/300, Loss: 0.010307657743624804, Test Accuracy: 46.01%\n",
            "Epoch 112/300, Loss: 0.010228422236815334, Test Accuracy: 45.94%\n",
            "Epoch 113/300, Loss: 0.010008778310156239, Test Accuracy: 45.71%\n",
            "Epoch 114/300, Loss: 0.00982312906577573, Test Accuracy: 45.90%\n",
            "Epoch 115/300, Loss: 0.009655637840870875, Test Accuracy: 45.97%\n",
            "Epoch 116/300, Loss: 0.009531338487335278, Test Accuracy: 45.94%\n",
            "Epoch 117/300, Loss: 0.009401967007755013, Test Accuracy: 45.97%\n",
            "Epoch 118/300, Loss: 0.009252358276530462, Test Accuracy: 46.02%\n",
            "Epoch 119/300, Loss: 0.00912051437683618, Test Accuracy: 46.00%\n",
            "Epoch 120/300, Loss: 0.009049014239890771, Test Accuracy: 45.96%\n",
            "Epoch 121/300, Loss: 0.008911560317269042, Test Accuracy: 46.02%\n",
            "Epoch 122/300, Loss: 0.008779681728043316, Test Accuracy: 45.82%\n",
            "Epoch 123/300, Loss: 0.00866087019009729, Test Accuracy: 45.84%\n",
            "Epoch 124/300, Loss: 0.008531520523903123, Test Accuracy: 45.81%\n",
            "Epoch 125/300, Loss: 0.008433672457680784, Test Accuracy: 45.83%\n",
            "Epoch 126/300, Loss: 0.008315954632968931, Test Accuracy: 46.06%\n",
            "Epoch 127/300, Loss: 0.008237582723766812, Test Accuracy: 45.97%\n",
            "Epoch 128/300, Loss: 0.008147244852170901, Test Accuracy: 45.84%\n",
            "Epoch 129/300, Loss: 0.008022824941222065, Test Accuracy: 45.81%\n",
            "Epoch 130/300, Loss: 0.007925619044408479, Test Accuracy: 46.05%\n",
            "Epoch 131/300, Loss: 0.007851372534166056, Test Accuracy: 46.08%\n",
            "Epoch 132/300, Loss: 0.0077666730896444065, Test Accuracy: 45.81%\n",
            "Epoch 133/300, Loss: 0.007641070154129086, Test Accuracy: 45.81%\n",
            "Epoch 134/300, Loss: 0.00754684237799037, Test Accuracy: 46.07%\n",
            "Epoch 135/300, Loss: 0.007504707040689452, Test Accuracy: 45.80%\n",
            "Epoch 136/300, Loss: 0.007392329271401321, Test Accuracy: 45.94%\n",
            "Epoch 137/300, Loss: 0.007316647835137824, Test Accuracy: 45.99%\n",
            "Epoch 138/300, Loss: 0.007219641217669938, Test Accuracy: 45.84%\n",
            "Epoch 139/300, Loss: 0.00715271535869366, Test Accuracy: 45.78%\n",
            "Epoch 140/300, Loss: 0.007077719439601648, Test Accuracy: 45.88%\n",
            "Epoch 141/300, Loss: 0.007090717438347423, Test Accuracy: 45.92%\n",
            "Epoch 142/300, Loss: 0.006923595439494896, Test Accuracy: 45.93%\n",
            "Epoch 143/300, Loss: 0.006845484640996281, Test Accuracy: 45.90%\n",
            "Epoch 144/300, Loss: 0.006767179527524346, Test Accuracy: 45.97%\n",
            "Epoch 145/300, Loss: 0.006720257040395646, Test Accuracy: 45.95%\n",
            "Epoch 146/300, Loss: 0.006626686942599766, Test Accuracy: 45.87%\n",
            "Epoch 147/300, Loss: 0.006559657915814119, Test Accuracy: 45.87%\n",
            "Epoch 148/300, Loss: 0.0065096716476355275, Test Accuracy: 45.75%\n",
            "Epoch 149/300, Loss: 0.006444778895632424, Test Accuracy: 45.85%\n",
            "Epoch 150/300, Loss: 0.006363591377075788, Test Accuracy: 45.74%\n",
            "Epoch 151/300, Loss: 0.006300557395222854, Test Accuracy: 45.90%\n",
            "Epoch 152/300, Loss: 0.006251943381252965, Test Accuracy: 45.72%\n",
            "Epoch 153/300, Loss: 0.006178737973903978, Test Accuracy: 45.81%\n",
            "Epoch 154/300, Loss: 0.006138812719146534, Test Accuracy: 45.98%\n",
            "Epoch 155/300, Loss: 0.006072444313486427, Test Accuracy: 45.74%\n",
            "Epoch 156/300, Loss: 0.0060099446998583776, Test Accuracy: 45.98%\n",
            "Epoch 157/300, Loss: 0.005952370739902441, Test Accuracy: 45.93%\n",
            "Epoch 158/300, Loss: 0.00590042026385174, Test Accuracy: 45.97%\n",
            "Epoch 159/300, Loss: 0.005872168786012194, Test Accuracy: 45.96%\n",
            "Epoch 160/300, Loss: 0.005792519733397932, Test Accuracy: 45.75%\n",
            "Epoch 161/300, Loss: 0.005733146927613224, Test Accuracy: 45.86%\n",
            "Epoch 162/300, Loss: 0.005687506650756242, Test Accuracy: 45.85%\n",
            "Epoch 163/300, Loss: 0.005651247261600927, Test Accuracy: 45.77%\n",
            "Epoch 164/300, Loss: 0.005586005682518953, Test Accuracy: 45.95%\n",
            "Epoch 165/300, Loss: 0.005540961323404876, Test Accuracy: 45.92%\n",
            "Epoch 166/300, Loss: 0.0054912050781975325, Test Accuracy: 45.87%\n",
            "Epoch 167/300, Loss: 0.005444516041402491, Test Accuracy: 45.89%\n",
            "Epoch 168/300, Loss: 0.005403446132955942, Test Accuracy: 45.86%\n",
            "Epoch 169/300, Loss: 0.0053567526634408355, Test Accuracy: 45.83%\n",
            "Epoch 170/300, Loss: 0.005310019907366987, Test Accuracy: 45.82%\n",
            "Epoch 171/300, Loss: 0.00525276216687855, Test Accuracy: 45.93%\n",
            "Epoch 172/300, Loss: 0.005213369821244165, Test Accuracy: 45.88%\n",
            "Epoch 173/300, Loss: 0.005179836719683583, Test Accuracy: 45.90%\n",
            "Epoch 174/300, Loss: 0.00513962398834946, Test Accuracy: 45.91%\n",
            "Epoch 175/300, Loss: 0.005101041505899774, Test Accuracy: 45.88%\n",
            "Epoch 176/300, Loss: 0.005054270929221352, Test Accuracy: 45.84%\n",
            "Epoch 177/300, Loss: 0.005017508355059297, Test Accuracy: 45.73%\n",
            "Epoch 178/300, Loss: 0.004969139708389581, Test Accuracy: 45.85%\n",
            "Epoch 179/300, Loss: 0.004936716749892354, Test Accuracy: 45.91%\n",
            "Epoch 180/300, Loss: 0.004895985242091381, Test Accuracy: 45.97%\n",
            "Epoch 181/300, Loss: 0.00484919499874625, Test Accuracy: 45.87%\n",
            "Epoch 182/300, Loss: 0.004817054410490683, Test Accuracy: 45.75%\n",
            "Epoch 183/300, Loss: 0.004775398669905021, Test Accuracy: 45.90%\n",
            "Epoch 184/300, Loss: 0.004745691811954287, Test Accuracy: 45.69%\n",
            "Epoch 185/300, Loss: 0.004704746547299875, Test Accuracy: 45.68%\n",
            "Epoch 186/300, Loss: 0.0046739634393070245, Test Accuracy: 45.92%\n",
            "Epoch 187/300, Loss: 0.004644829999138282, Test Accuracy: 45.65%\n",
            "Epoch 188/300, Loss: 0.0046043135160228725, Test Accuracy: 45.85%\n",
            "Epoch 189/300, Loss: 0.004570262356448539, Test Accuracy: 45.66%\n",
            "Epoch 190/300, Loss: 0.004541466671315642, Test Accuracy: 45.69%\n",
            "Epoch 191/300, Loss: 0.004500113348837082, Test Accuracy: 45.71%\n",
            "Epoch 192/300, Loss: 0.004471920339941206, Test Accuracy: 45.84%\n",
            "Epoch 193/300, Loss: 0.004437369223855679, Test Accuracy: 45.84%\n",
            "Epoch 194/300, Loss: 0.004410071136407264, Test Accuracy: 45.87%\n",
            "Epoch 195/300, Loss: 0.004375665821909657, Test Accuracy: 45.80%\n",
            "Epoch 196/300, Loss: 0.004341012222206152, Test Accuracy: 45.69%\n",
            "Epoch 197/300, Loss: 0.004317988382660744, Test Accuracy: 45.74%\n",
            "Epoch 198/300, Loss: 0.004288743131347739, Test Accuracy: 45.79%\n",
            "Epoch 199/300, Loss: 0.004256024923484226, Test Accuracy: 45.79%\n",
            "Epoch 200/300, Loss: 0.004228431621527088, Test Accuracy: 45.75%\n",
            "Epoch 201/300, Loss: 0.004208186066781558, Test Accuracy: 45.84%\n",
            "Epoch 202/300, Loss: 0.0041686894823615315, Test Accuracy: 45.87%\n",
            "Epoch 203/300, Loss: 0.004149320587797075, Test Accuracy: 45.81%\n",
            "Epoch 204/300, Loss: 0.004115974509573744, Test Accuracy: 45.64%\n",
            "Epoch 205/300, Loss: 0.004088752895596026, Test Accuracy: 45.75%\n",
            "Epoch 206/300, Loss: 0.004062915516848022, Test Accuracy: 45.74%\n",
            "Epoch 207/300, Loss: 0.0040355828085405394, Test Accuracy: 45.76%\n",
            "Epoch 208/300, Loss: 0.00401132908647955, Test Accuracy: 45.81%\n",
            "Epoch 209/300, Loss: 0.00398214256755295, Test Accuracy: 45.74%\n",
            "Epoch 210/300, Loss: 0.003953710187230109, Test Accuracy: 45.78%\n",
            "Epoch 211/300, Loss: 0.003929035707572934, Test Accuracy: 45.80%\n",
            "Epoch 212/300, Loss: 0.003908507072847034, Test Accuracy: 45.67%\n",
            "Epoch 213/300, Loss: 0.003877054770630251, Test Accuracy: 45.73%\n",
            "Epoch 214/300, Loss: 0.0038571496852670612, Test Accuracy: 45.88%\n",
            "Epoch 215/300, Loss: 0.0038310212776737, Test Accuracy: 45.88%\n",
            "Epoch 216/300, Loss: 0.0038113118720169985, Test Accuracy: 45.87%\n",
            "Epoch 217/300, Loss: 0.0037857962281265018, Test Accuracy: 45.81%\n",
            "Epoch 218/300, Loss: 0.0037624528211489634, Test Accuracy: 45.76%\n",
            "Epoch 219/300, Loss: 0.0037412279064576986, Test Accuracy: 45.76%\n",
            "Epoch 220/300, Loss: 0.00371136761251694, Test Accuracy: 45.70%\n",
            "Epoch 221/300, Loss: 0.0036936521861447177, Test Accuracy: 45.81%\n",
            "Epoch 222/300, Loss: 0.003666829641730246, Test Accuracy: 45.78%\n",
            "Epoch 223/300, Loss: 0.0036486858445870965, Test Accuracy: 45.84%\n",
            "Epoch 224/300, Loss: 0.003629487482529975, Test Accuracy: 45.68%\n",
            "Epoch 225/300, Loss: 0.0036086827111820752, Test Accuracy: 45.78%\n",
            "Epoch 226/300, Loss: 0.003582780181712716, Test Accuracy: 45.66%\n",
            "Epoch 227/300, Loss: 0.0035641106059035896, Test Accuracy: 45.77%\n",
            "Epoch 228/300, Loss: 0.0035413711537206002, Test Accuracy: 45.67%\n",
            "Epoch 229/300, Loss: 0.0035261159959521504, Test Accuracy: 45.80%\n",
            "Epoch 230/300, Loss: 0.0035056009328097667, Test Accuracy: 45.69%\n",
            "Epoch 231/300, Loss: 0.0034849155717037775, Test Accuracy: 45.77%\n",
            "Epoch 232/300, Loss: 0.003463819136179302, Test Accuracy: 45.70%\n",
            "Epoch 233/300, Loss: 0.0034398287796145468, Test Accuracy: 45.84%\n",
            "Epoch 234/300, Loss: 0.003423698400656716, Test Accuracy: 45.76%\n",
            "Epoch 235/300, Loss: 0.0034045296846588052, Test Accuracy: 45.68%\n",
            "Epoch 236/300, Loss: 0.003384860265840343, Test Accuracy: 45.71%\n",
            "Epoch 237/300, Loss: 0.0033651118156168267, Test Accuracy: 45.75%\n",
            "Epoch 238/300, Loss: 0.0033505360599755, Test Accuracy: 45.66%\n",
            "Epoch 239/300, Loss: 0.0033265158270532774, Test Accuracy: 45.76%\n",
            "Epoch 240/300, Loss: 0.0033104051013554013, Test Accuracy: 45.74%\n",
            "Epoch 241/300, Loss: 0.0032903750797838535, Test Accuracy: 45.78%\n",
            "Epoch 242/300, Loss: 0.0032757957116924157, Test Accuracy: 45.67%\n",
            "Epoch 243/300, Loss: 0.0032574206476546083, Test Accuracy: 45.73%\n",
            "Epoch 244/300, Loss: 0.003239659191870744, Test Accuracy: 45.87%\n",
            "Epoch 245/300, Loss: 0.0032218377322187353, Test Accuracy: 45.70%\n",
            "Epoch 246/300, Loss: 0.0032090632359199917, Test Accuracy: 45.71%\n",
            "Epoch 247/300, Loss: 0.0031857306653990036, Test Accuracy: 45.81%\n",
            "Epoch 248/300, Loss: 0.003171215737768838, Test Accuracy: 45.73%\n",
            "Epoch 249/300, Loss: 0.0031545296162712464, Test Accuracy: 45.74%\n",
            "Epoch 250/300, Loss: 0.0031412176347515824, Test Accuracy: 45.65%\n",
            "Epoch 251/300, Loss: 0.0031222789689108387, Test Accuracy: 45.69%\n",
            "Epoch 252/300, Loss: 0.0031041359554669955, Test Accuracy: 45.86%\n",
            "Epoch 253/300, Loss: 0.0030883212527796455, Test Accuracy: 45.67%\n",
            "Epoch 254/300, Loss: 0.0030730105748087862, Test Accuracy: 45.78%\n",
            "Epoch 255/300, Loss: 0.003056519607249445, Test Accuracy: 45.86%\n",
            "Epoch 256/300, Loss: 0.003042435181840792, Test Accuracy: 45.74%\n",
            "Epoch 257/300, Loss: 0.003029146700276995, Test Accuracy: 45.75%\n",
            "Epoch 258/300, Loss: 0.0030111415582510593, Test Accuracy: 45.73%\n",
            "Epoch 259/300, Loss: 0.0029976938457763917, Test Accuracy: 45.83%\n",
            "Epoch 260/300, Loss: 0.0029861513365558225, Test Accuracy: 45.68%\n",
            "Epoch 261/300, Loss: 0.0029698501485390964, Test Accuracy: 45.91%\n",
            "Epoch 262/300, Loss: 0.002951636516354425, Test Accuracy: 45.77%\n",
            "Epoch 263/300, Loss: 0.0029385944785042567, Test Accuracy: 45.71%\n",
            "Epoch 264/300, Loss: 0.0029263722210388417, Test Accuracy: 45.79%\n",
            "Epoch 265/300, Loss: 0.0029107825143855023, Test Accuracy: 45.80%\n",
            "Epoch 266/300, Loss: 0.0028951929166992877, Test Accuracy: 45.68%\n",
            "Epoch 267/300, Loss: 0.0028814193593029477, Test Accuracy: 45.79%\n",
            "Epoch 268/300, Loss: 0.002867730286136813, Test Accuracy: 45.78%\n",
            "Epoch 269/300, Loss: 0.002853699518806794, Test Accuracy: 45.67%\n",
            "Epoch 270/300, Loss: 0.0028404776393945353, Test Accuracy: 45.64%\n",
            "Epoch 271/300, Loss: 0.002827458183137522, Test Accuracy: 45.65%\n",
            "Epoch 272/300, Loss: 0.0028141656358263343, Test Accuracy: 45.77%\n",
            "Epoch 273/300, Loss: 0.002797279441154187, Test Accuracy: 45.75%\n",
            "Epoch 274/300, Loss: 0.0027859313705470116, Test Accuracy: 45.81%\n",
            "Epoch 275/300, Loss: 0.002773599991853744, Test Accuracy: 45.72%\n",
            "Epoch 276/300, Loss: 0.002760119458078928, Test Accuracy: 45.68%\n",
            "Epoch 277/300, Loss: 0.0027462949631324543, Test Accuracy: 45.65%\n",
            "Epoch 278/300, Loss: 0.002735559340945957, Test Accuracy: 45.80%\n",
            "Epoch 279/300, Loss: 0.002722465788831747, Test Accuracy: 45.82%\n",
            "Epoch 280/300, Loss: 0.0027100125956930035, Test Accuracy: 45.71%\n",
            "Epoch 281/300, Loss: 0.002696790963560891, Test Accuracy: 45.75%\n",
            "Epoch 282/300, Loss: 0.002688020471556759, Test Accuracy: 45.83%\n",
            "Epoch 283/300, Loss: 0.0026752151661628165, Test Accuracy: 45.72%\n",
            "Epoch 284/300, Loss: 0.0026620642702296013, Test Accuracy: 45.76%\n",
            "Epoch 285/300, Loss: 0.0026485080489178528, Test Accuracy: 45.67%\n",
            "Epoch 286/300, Loss: 0.0026380574858466776, Test Accuracy: 45.74%\n",
            "Epoch 287/300, Loss: 0.002625837715110853, Test Accuracy: 45.69%\n",
            "Epoch 288/300, Loss: 0.002614506280796885, Test Accuracy: 45.76%\n",
            "Epoch 289/300, Loss: 0.0026021390453651928, Test Accuracy: 45.61%\n",
            "Epoch 290/300, Loss: 0.002591549860470245, Test Accuracy: 45.77%\n",
            "Epoch 291/300, Loss: 0.002581711703141578, Test Accuracy: 45.74%\n",
            "Epoch 292/300, Loss: 0.002569923296830571, Test Accuracy: 45.69%\n",
            "Epoch 293/300, Loss: 0.0025575494827042434, Test Accuracy: 45.67%\n",
            "Epoch 294/300, Loss: 0.0025463292910136467, Test Accuracy: 45.70%\n",
            "Epoch 295/300, Loss: 0.00253515779250793, Test Accuracy: 45.68%\n",
            "Epoch 296/300, Loss: 0.0025253969344315825, Test Accuracy: 45.70%\n",
            "Epoch 297/300, Loss: 0.0025140258227519677, Test Accuracy: 45.80%\n",
            "Epoch 298/300, Loss: 0.0025043091189291423, Test Accuracy: 45.72%\n",
            "Epoch 299/300, Loss: 0.002492132710480034, Test Accuracy: 45.66%\n",
            "Epoch 300/300, Loss: 0.0024821913834799482, Test Accuracy: 45.74%\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.53      0.53      1000\n",
            "           1       0.59      0.53      0.56      1000\n",
            "           2       0.32      0.36      0.34      1000\n",
            "           3       0.31      0.30      0.30      1000\n",
            "           4       0.40      0.40      0.40      1000\n",
            "           5       0.35      0.34      0.35      1000\n",
            "           6       0.48      0.50      0.49      1000\n",
            "           7       0.51      0.47      0.49      1000\n",
            "           8       0.59      0.62      0.61      1000\n",
            "           9       0.53      0.50      0.52      1000\n",
            "\n",
            "    accuracy                           0.46     10000\n",
            "   macro avg       0.46      0.46      0.46     10000\n",
            "weighted avg       0.46      0.46      0.46     10000\n",
            "\n",
            "time: 1h 33min 32s (started: 2023-11-30 23:35:37 +00:00)\n"
          ]
        }
      ],
      "source": [
        "train_model(model, train_loader, test_loader, num_epochs=300, lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwT6edYguxUz",
        "outputId": "f12b5510-3701-436f-beef-d3ac9051c14f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 5.55 s (started: 2023-12-02 01:01:32 +00:00)\n"
          ]
        }
      ],
      "source": [
        "model2 = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(32 * 32 * 3, 512),\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(512, 256),\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(256, 128),\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(128, 10)\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tf4CmrcvQvg",
        "outputId": "125d3c98-3577-4c20-88f3-880807d04016"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200, Loss: 1.8592360516961233, Test Accuracy: 39.53%\n",
            "Epoch 2/200, Loss: 1.689475319664675, Test Accuracy: 42.41%\n",
            "Epoch 3/200, Loss: 1.6198919219842571, Test Accuracy: 43.72%\n",
            "Epoch 4/200, Loss: 1.5600317946932518, Test Accuracy: 45.21%\n",
            "Epoch 5/200, Loss: 1.5012287019310437, Test Accuracy: 46.19%\n",
            "Epoch 6/200, Loss: 1.444315607434881, Test Accuracy: 46.07%\n",
            "Epoch 7/200, Loss: 1.3895388086179243, Test Accuracy: 47.66%\n",
            "Epoch 8/200, Loss: 1.3318402658878652, Test Accuracy: 47.47%\n",
            "Epoch 9/200, Loss: 1.2729721801142164, Test Accuracy: 48.02%\n",
            "Epoch 10/200, Loss: 1.2156133362290498, Test Accuracy: 46.54%\n",
            "Epoch 11/200, Loss: 1.1530542257727527, Test Accuracy: 47.28%\n",
            "Epoch 12/200, Loss: 1.0960718936746272, Test Accuracy: 48.45%\n",
            "Epoch 13/200, Loss: 1.0335739719814319, Test Accuracy: 48.03%\n",
            "Epoch 14/200, Loss: 0.9749154275377363, Test Accuracy: 47.35%\n",
            "Epoch 15/200, Loss: 0.9124068804109089, Test Accuracy: 44.84%\n",
            "Epoch 16/200, Loss: 0.854338770292542, Test Accuracy: 48.47%\n",
            "Epoch 17/200, Loss: 0.7949728493460156, Test Accuracy: 45.26%\n",
            "Epoch 18/200, Loss: 0.738216815948944, Test Accuracy: 47.31%\n",
            "Epoch 19/200, Loss: 0.6870404595434094, Test Accuracy: 47.72%\n",
            "Epoch 20/200, Loss: 0.6331846248775587, Test Accuracy: 46.83%\n",
            "Epoch 21/200, Loss: 0.5793993251966653, Test Accuracy: 46.06%\n",
            "Epoch 22/200, Loss: 0.5361505795272588, Test Accuracy: 43.25%\n",
            "Epoch 23/200, Loss: 0.4976326654202192, Test Accuracy: 45.42%\n",
            "Epoch 24/200, Loss: 0.4526727920873609, Test Accuracy: 46.13%\n",
            "Epoch 25/200, Loss: 0.40936532240987816, Test Accuracy: 45.33%\n",
            "Epoch 26/200, Loss: 0.3733251312138633, Test Accuracy: 46.18%\n",
            "Epoch 27/200, Loss: 0.33961396374080094, Test Accuracy: 46.80%\n",
            "Epoch 28/200, Loss: 0.3007981456954435, Test Accuracy: 45.46%\n",
            "Epoch 29/200, Loss: 0.27259894342221896, Test Accuracy: 46.28%\n",
            "Epoch 30/200, Loss: 0.2521174307114141, Test Accuracy: 45.06%\n",
            "Epoch 31/200, Loss: 0.22532208329418188, Test Accuracy: 45.39%\n",
            "Epoch 32/200, Loss: 0.20310966406429873, Test Accuracy: 46.43%\n",
            "Epoch 33/200, Loss: 0.1756775781526561, Test Accuracy: 44.52%\n",
            "Epoch 34/200, Loss: 0.16452678783021518, Test Accuracy: 44.90%\n",
            "Epoch 35/200, Loss: 0.15293220091570628, Test Accuracy: 46.47%\n",
            "Epoch 36/200, Loss: 0.13051490359406343, Test Accuracy: 45.10%\n",
            "Epoch 37/200, Loss: 0.12041237024007626, Test Accuracy: 46.20%\n",
            "Epoch 38/200, Loss: 0.10654526459314144, Test Accuracy: 45.99%\n",
            "Epoch 39/200, Loss: 0.08388035720266683, Test Accuracy: 45.85%\n",
            "Epoch 40/200, Loss: 0.07339535870572036, Test Accuracy: 46.79%\n",
            "Epoch 41/200, Loss: 0.057230930763188935, Test Accuracy: 45.91%\n",
            "Epoch 42/200, Loss: 0.04925761784957775, Test Accuracy: 46.10%\n",
            "Epoch 43/200, Loss: 0.04373568879626334, Test Accuracy: 45.91%\n",
            "Epoch 44/200, Loss: 0.04258946096688457, Test Accuracy: 46.58%\n",
            "Epoch 45/200, Loss: 0.030409771496798278, Test Accuracy: 46.42%\n",
            "Epoch 46/200, Loss: 0.02566820120597431, Test Accuracy: 45.16%\n",
            "Epoch 47/200, Loss: 0.02560519441719133, Test Accuracy: 46.73%\n",
            "Epoch 48/200, Loss: 0.0246436581122394, Test Accuracy: 45.69%\n",
            "Epoch 49/200, Loss: 0.015345142866614122, Test Accuracy: 46.42%\n",
            "Epoch 50/200, Loss: 0.007954421552760325, Test Accuracy: 46.72%\n",
            "Epoch 51/200, Loss: 0.006280433721211754, Test Accuracy: 46.71%\n",
            "Epoch 52/200, Loss: 0.008466464260510233, Test Accuracy: 46.87%\n",
            "Epoch 53/200, Loss: 0.01093173041532766, Test Accuracy: 43.87%\n",
            "Epoch 54/200, Loss: 0.010294180784910149, Test Accuracy: 46.50%\n",
            "Epoch 55/200, Loss: 0.004484285919377979, Test Accuracy: 46.72%\n",
            "Epoch 56/200, Loss: 0.0033244324128708955, Test Accuracy: 46.56%\n",
            "Epoch 57/200, Loss: 0.0023657632328409604, Test Accuracy: 46.45%\n",
            "Epoch 58/200, Loss: 0.00212444114325698, Test Accuracy: 46.43%\n",
            "Epoch 59/200, Loss: 0.0019170625513447515, Test Accuracy: 46.54%\n",
            "Epoch 60/200, Loss: 0.0018145475724353904, Test Accuracy: 46.44%\n",
            "Epoch 61/200, Loss: 0.0017322193564299222, Test Accuracy: 46.40%\n",
            "Epoch 62/200, Loss: 0.0016624470073708898, Test Accuracy: 46.33%\n",
            "Epoch 63/200, Loss: 0.0015734378139150846, Test Accuracy: 46.62%\n",
            "Epoch 64/200, Loss: 0.001500267599726016, Test Accuracy: 46.42%\n",
            "Epoch 65/200, Loss: 0.0014376359069567968, Test Accuracy: 46.39%\n",
            "Epoch 66/200, Loss: 0.0013775324887232302, Test Accuracy: 46.36%\n",
            "Epoch 67/200, Loss: 0.0013315156747939175, Test Accuracy: 46.53%\n",
            "Epoch 68/200, Loss: 0.0012817292343159233, Test Accuracy: 46.35%\n",
            "Epoch 69/200, Loss: 0.0012396600913963688, Test Accuracy: 46.35%\n",
            "Epoch 70/200, Loss: 0.0012009819177307382, Test Accuracy: 46.47%\n",
            "Epoch 71/200, Loss: 0.0011669578716609929, Test Accuracy: 46.49%\n",
            "Epoch 72/200, Loss: 0.0011345285819727218, Test Accuracy: 46.51%\n",
            "Epoch 73/200, Loss: 0.0011013924479824197, Test Accuracy: 46.44%\n",
            "Epoch 74/200, Loss: 0.0010764571854355194, Test Accuracy: 46.46%\n",
            "Epoch 75/200, Loss: 0.001046891259143465, Test Accuracy: 46.49%\n",
            "Epoch 76/200, Loss: 0.001017356023054763, Test Accuracy: 46.35%\n",
            "Epoch 77/200, Loss: 0.000992815482558418, Test Accuracy: 46.44%\n",
            "Epoch 78/200, Loss: 0.0009692596369838581, Test Accuracy: 46.53%\n",
            "Epoch 79/200, Loss: 0.0009470333867204052, Test Accuracy: 46.33%\n",
            "Epoch 80/200, Loss: 0.0009258156121502584, Test Accuracy: 46.49%\n",
            "Epoch 81/200, Loss: 0.0009074356343319505, Test Accuracy: 46.36%\n",
            "Epoch 82/200, Loss: 0.000886903687914141, Test Accuracy: 46.34%\n",
            "Epoch 83/200, Loss: 0.0008667951907592534, Test Accuracy: 46.47%\n",
            "Epoch 84/200, Loss: 0.0008504173010776876, Test Accuracy: 46.41%\n",
            "Epoch 85/200, Loss: 0.0008329477939077385, Test Accuracy: 46.44%\n",
            "Epoch 86/200, Loss: 0.0008179703364823542, Test Accuracy: 46.40%\n",
            "Epoch 87/200, Loss: 0.0008008978434246073, Test Accuracy: 46.34%\n",
            "Epoch 88/200, Loss: 0.0007865430829530076, Test Accuracy: 46.36%\n",
            "Epoch 89/200, Loss: 0.0007710527960272561, Test Accuracy: 46.37%\n",
            "Epoch 90/200, Loss: 0.0007575388939287609, Test Accuracy: 46.43%\n",
            "Epoch 91/200, Loss: 0.000742772006189453, Test Accuracy: 46.46%\n",
            "Epoch 92/200, Loss: 0.0007300100514444184, Test Accuracy: 46.41%\n",
            "Epoch 93/200, Loss: 0.0007191371959736166, Test Accuracy: 46.47%\n",
            "Epoch 94/200, Loss: 0.0007055892400566152, Test Accuracy: 46.42%\n",
            "Epoch 95/200, Loss: 0.0006953960529952957, Test Accuracy: 46.44%\n",
            "Epoch 96/200, Loss: 0.0006833464980136003, Test Accuracy: 46.50%\n",
            "Epoch 97/200, Loss: 0.000672400114787531, Test Accuracy: 46.42%\n",
            "Epoch 98/200, Loss: 0.0006620589079720701, Test Accuracy: 46.44%\n",
            "Epoch 99/200, Loss: 0.0006509697258894607, Test Accuracy: 46.43%\n",
            "Epoch 100/200, Loss: 0.0006416992286815453, Test Accuracy: 46.41%\n",
            "Epoch 101/200, Loss: 0.0006319903853229174, Test Accuracy: 46.49%\n",
            "Epoch 102/200, Loss: 0.000622254876580485, Test Accuracy: 46.48%\n",
            "Epoch 103/200, Loss: 0.0006138441319039934, Test Accuracy: 46.49%\n",
            "Epoch 104/200, Loss: 0.000604555563656649, Test Accuracy: 46.48%\n",
            "Epoch 105/200, Loss: 0.000595883878328306, Test Accuracy: 46.51%\n",
            "Epoch 106/200, Loss: 0.0005879607829668244, Test Accuracy: 46.50%\n",
            "Epoch 107/200, Loss: 0.0005802510933507674, Test Accuracy: 46.54%\n",
            "Epoch 108/200, Loss: 0.0005720060508116074, Test Accuracy: 46.48%\n",
            "Epoch 109/200, Loss: 0.0005639887928928595, Test Accuracy: 46.47%\n",
            "Epoch 110/200, Loss: 0.0005572314848189355, Test Accuracy: 46.38%\n",
            "Epoch 111/200, Loss: 0.0005500564511050694, Test Accuracy: 46.42%\n",
            "Epoch 112/200, Loss: 0.0005426397176019392, Test Accuracy: 46.43%\n",
            "Epoch 113/200, Loss: 0.0005353400181237547, Test Accuracy: 46.43%\n",
            "Epoch 114/200, Loss: 0.0005285911478982733, Test Accuracy: 46.42%\n",
            "Epoch 115/200, Loss: 0.0005229953261038976, Test Accuracy: 46.47%\n",
            "Epoch 116/200, Loss: 0.0005158675569175908, Test Accuracy: 46.50%\n",
            "Epoch 117/200, Loss: 0.0005101619047478544, Test Accuracy: 46.46%\n",
            "Epoch 118/200, Loss: 0.0005040758763697958, Test Accuracy: 46.38%\n",
            "Epoch 119/200, Loss: 0.0004979433040725996, Test Accuracy: 46.44%\n",
            "Epoch 120/200, Loss: 0.0004920396255161666, Test Accuracy: 46.50%\n",
            "Epoch 121/200, Loss: 0.00048627961240470485, Test Accuracy: 46.46%\n",
            "Epoch 122/200, Loss: 0.0004811484168123654, Test Accuracy: 46.42%\n",
            "Epoch 123/200, Loss: 0.00047540135058550244, Test Accuracy: 46.48%\n",
            "Epoch 124/200, Loss: 0.00047005794166686505, Test Accuracy: 46.39%\n",
            "Epoch 125/200, Loss: 0.0004650460171841129, Test Accuracy: 46.43%\n",
            "Epoch 126/200, Loss: 0.00045958481099583464, Test Accuracy: 46.45%\n",
            "Epoch 127/200, Loss: 0.0004548588037910625, Test Accuracy: 46.39%\n",
            "Epoch 128/200, Loss: 0.0004496895962965157, Test Accuracy: 46.41%\n",
            "Epoch 129/200, Loss: 0.00044535123448913067, Test Accuracy: 46.48%\n",
            "Epoch 130/200, Loss: 0.00044059838156108, Test Accuracy: 46.41%\n",
            "Epoch 131/200, Loss: 0.0004359928253254992, Test Accuracy: 46.46%\n",
            "Epoch 132/200, Loss: 0.0004311836020298831, Test Accuracy: 46.45%\n",
            "Epoch 133/200, Loss: 0.00042744257113978536, Test Accuracy: 46.46%\n",
            "Epoch 134/200, Loss: 0.0004229648921263189, Test Accuracy: 46.42%\n",
            "Epoch 135/200, Loss: 0.00041863700000297963, Test Accuracy: 46.38%\n",
            "Epoch 136/200, Loss: 0.0004143560620501336, Test Accuracy: 46.41%\n",
            "Epoch 137/200, Loss: 0.0004104933503817681, Test Accuracy: 46.43%\n",
            "Epoch 138/200, Loss: 0.0004064649489773193, Test Accuracy: 46.44%\n",
            "Epoch 139/200, Loss: 0.00040284114185499024, Test Accuracy: 46.44%\n",
            "Epoch 140/200, Loss: 0.0003985961694168332, Test Accuracy: 46.36%\n",
            "Epoch 141/200, Loss: 0.0003948923042532273, Test Accuracy: 46.49%\n",
            "Epoch 142/200, Loss: 0.00039128218766677856, Test Accuracy: 46.39%\n",
            "Epoch 143/200, Loss: 0.0003878011653704482, Test Accuracy: 46.42%\n",
            "Epoch 144/200, Loss: 0.00038403913078776617, Test Accuracy: 46.48%\n",
            "Epoch 145/200, Loss: 0.00038063191879406317, Test Accuracy: 46.34%\n",
            "Epoch 146/200, Loss: 0.00037723295430081374, Test Accuracy: 46.42%\n",
            "Epoch 147/200, Loss: 0.00037367686926888065, Test Accuracy: 46.36%\n",
            "Epoch 148/200, Loss: 0.0003705327471788056, Test Accuracy: 46.42%\n",
            "Epoch 149/200, Loss: 0.00036734477915333064, Test Accuracy: 46.51%\n",
            "Epoch 150/200, Loss: 0.00036402796417840005, Test Accuracy: 46.46%\n",
            "Epoch 151/200, Loss: 0.00036081125944410704, Test Accuracy: 46.46%\n",
            "Epoch 152/200, Loss: 0.00035778031986966784, Test Accuracy: 46.42%\n",
            "Epoch 153/200, Loss: 0.0003548201050890743, Test Accuracy: 46.49%\n",
            "Epoch 154/200, Loss: 0.00035203554483859904, Test Accuracy: 46.45%\n",
            "Epoch 155/200, Loss: 0.0003487582976104732, Test Accuracy: 46.47%\n",
            "Epoch 156/200, Loss: 0.00034615583065174754, Test Accuracy: 46.36%\n",
            "Epoch 157/200, Loss: 0.00034325879556678057, Test Accuracy: 46.38%\n",
            "Epoch 158/200, Loss: 0.00034033821505935794, Test Accuracy: 46.51%\n",
            "Epoch 159/200, Loss: 0.0003374385576596813, Test Accuracy: 46.45%\n",
            "Epoch 160/200, Loss: 0.0003347848797321584, Test Accuracy: 46.46%\n",
            "Epoch 161/200, Loss: 0.0003321995567636903, Test Accuracy: 46.42%\n",
            "Epoch 162/200, Loss: 0.00032975105650696765, Test Accuracy: 46.44%\n",
            "Epoch 163/200, Loss: 0.00032728220176580196, Test Accuracy: 46.49%\n",
            "Epoch 164/200, Loss: 0.0003246223338557436, Test Accuracy: 46.42%\n",
            "Epoch 165/200, Loss: 0.00032183354558959135, Test Accuracy: 46.52%\n",
            "Epoch 166/200, Loss: 0.00031951799130919154, Test Accuracy: 46.44%\n",
            "Epoch 167/200, Loss: 0.000317093223210538, Test Accuracy: 46.47%\n",
            "Epoch 168/200, Loss: 0.0003145939404937669, Test Accuracy: 46.44%\n",
            "Epoch 169/200, Loss: 0.00031231628305954866, Test Accuracy: 46.48%\n",
            "Epoch 170/200, Loss: 0.00031010211228443813, Test Accuracy: 46.47%\n",
            "Epoch 171/200, Loss: 0.00030773879114678605, Test Accuracy: 46.39%\n",
            "Epoch 172/200, Loss: 0.00030529697837958426, Test Accuracy: 46.44%\n",
            "Epoch 173/200, Loss: 0.0003031977120874347, Test Accuracy: 46.53%\n",
            "Epoch 174/200, Loss: 0.00030074369253505645, Test Accuracy: 46.46%\n",
            "Epoch 175/200, Loss: 0.00029896519434769706, Test Accuracy: 46.44%\n",
            "Epoch 176/200, Loss: 0.00029681689513977425, Test Accuracy: 46.46%\n",
            "Epoch 177/200, Loss: 0.0002945826388951373, Test Accuracy: 46.45%\n",
            "Epoch 178/200, Loss: 0.00029247474011453257, Test Accuracy: 46.46%\n",
            "Epoch 179/200, Loss: 0.0002905648367640548, Test Accuracy: 46.45%\n",
            "Epoch 180/200, Loss: 0.0002884335885882337, Test Accuracy: 46.40%\n",
            "Epoch 181/200, Loss: 0.00028645260246027847, Test Accuracy: 46.38%\n",
            "Epoch 182/200, Loss: 0.00028448899981470586, Test Accuracy: 46.46%\n",
            "Epoch 183/200, Loss: 0.00028259078140077985, Test Accuracy: 46.46%\n",
            "Epoch 184/200, Loss: 0.00028051839731876475, Test Accuracy: 46.47%\n",
            "Epoch 185/200, Loss: 0.00027854464634161346, Test Accuracy: 46.43%\n",
            "Epoch 186/200, Loss: 0.00027699207420740486, Test Accuracy: 46.39%\n",
            "Epoch 187/200, Loss: 0.00027501248187455213, Test Accuracy: 46.41%\n",
            "Epoch 188/200, Loss: 0.00027306014971990975, Test Accuracy: 46.41%\n",
            "Epoch 189/200, Loss: 0.0002712914508136787, Test Accuracy: 46.45%\n",
            "Epoch 190/200, Loss: 0.00026957265913915644, Test Accuracy: 46.40%\n",
            "Epoch 191/200, Loss: 0.0002678498782335035, Test Accuracy: 46.42%\n",
            "Epoch 192/200, Loss: 0.0002661791507063686, Test Accuracy: 46.36%\n",
            "Epoch 193/200, Loss: 0.0002644381776070493, Test Accuracy: 46.43%\n",
            "Epoch 194/200, Loss: 0.00026278261766777633, Test Accuracy: 46.45%\n",
            "Epoch 195/200, Loss: 0.0002610377854061246, Test Accuracy: 46.40%\n",
            "Epoch 196/200, Loss: 0.0002594799321463304, Test Accuracy: 46.39%\n",
            "Epoch 197/200, Loss: 0.0002577614263382708, Test Accuracy: 46.42%\n",
            "Epoch 198/200, Loss: 0.0002561873393184303, Test Accuracy: 46.41%\n",
            "Epoch 199/200, Loss: 0.0002544400403721488, Test Accuracy: 46.42%\n",
            "Epoch 200/200, Loss: 0.00025303474049566827, Test Accuracy: 46.37%\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.55      0.54      1000\n",
            "           1       0.60      0.55      0.57      1000\n",
            "           2       0.35      0.35      0.35      1000\n",
            "           3       0.29      0.31      0.30      1000\n",
            "           4       0.40      0.40      0.40      1000\n",
            "           5       0.35      0.35      0.35      1000\n",
            "           6       0.51      0.51      0.51      1000\n",
            "           7       0.52      0.49      0.50      1000\n",
            "           8       0.60      0.62      0.61      1000\n",
            "           9       0.54      0.50      0.52      1000\n",
            "\n",
            "    accuracy                           0.46     10000\n",
            "   macro avg       0.47      0.46      0.46     10000\n",
            "weighted avg       0.47      0.46      0.46     10000\n",
            "\n",
            "time: 1h 2min 41s (started: 2023-12-02 01:01:38 +00:00)\n"
          ]
        }
      ],
      "source": [
        "train_model(model2, train_loader, test_loader, num_epochs=200, lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "9vKJXg9BYOtj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9102fa8-dbc7-4a5f-b791-5f5d55eee564"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of trainable parameters  1738890 \n",
            "\n",
            "time: 1.24 ms (started: 2023-12-02 02:09:44 +00:00)\n"
          ]
        }
      ],
      "source": [
        "total_params = sum(p.numel() for p in model2.parameters() if p.requires_grad)\n",
        "print(\"Total number of trainable parameters \", total_params,  '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sKoymvifSfNN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMkrgnT9LdfIUDapA1UzJ9/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}