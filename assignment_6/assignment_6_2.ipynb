{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM+Lg2iqEc/MOGKNkumOi9a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dhanush-adk/machine_learning/blob/main/assignment_6/assignment_6_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipython-autotime\n",
        "%load_ext autotime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AomgVJDmg49Q",
        "outputId": "67da1483-84c0-4f63-bd83-8e4c953c1fa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ipython-autotime\n",
            "  Downloading ipython_autotime-0.3.2-py2.py3-none-any.whl (7.0 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from ipython-autotime) (7.34.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython->ipython-autotime)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (3.0.41)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->ipython-autotime) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->ipython-autotime) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ipython-autotime) (0.2.10)\n",
            "Installing collected packages: jedi, ipython-autotime\n",
            "Successfully installed ipython-autotime-0.3.2 jedi-0.19.1\n",
            "time: 252 µs (started: 2023-11-30 23:15:15 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEdC6LDkQ4XS",
        "outputId": "5cb19621-4f6e-41e0-c433-b1907ecf5fe3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 926 µs (started: 2023-11-30 23:15:15 +00:00)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchvision import datasets, transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXlQeX-1R-ia",
        "outputId": "0ba60d39-e62e-45e8-ffc3-246c57b81c00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7ccc0537d390>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.41 ms (started: 2023-11-30 23:15:15 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "# Calculate mean and std\n",
        "imgs = torch.stack([img_t for img_t, _ in train_dataset], dim=3)\n",
        "mean = imgs.view(3, -1).mean(dim=1)\n",
        "std = imgs.view(3, -1).std(dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsiQp8c3Ux_Q",
        "outputId": "43ee1ef8-70ff-4b5b-d3c9-4336538396e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "time: 24 s (started: 2023-11-30 23:15:15 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jooydkvUVt8n",
        "outputId": "d3cbd602-2685-436b-f1c9-217cda8326ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4914, 0.4822, 0.4465])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.92 ms (started: 2023-11-30 23:15:39 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "std"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XC98Saf9VuvN",
        "outputId": "8dc9dd60-fc85-4352-a012-4d85a5fdc3e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2470, 0.2435, 0.2616])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.02 ms (started: 2023-11-30 23:15:39 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJjBdJ1VU-TY",
        "outputId": "810dbf49-8008-40f4-cd72-aeb517346549"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 618 µs (started: 2023-11-30 23:15:43 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIRtCChAV2nr",
        "outputId": "d201d9b2-38b2-4c08-e749-9d48dc2a42e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 50
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.83 ms (started: 2023-11-30 23:15:44 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformation with calculated mean and std\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aItV66gmV1zl",
        "outputId": "42f11606-934a-46f9-e013-197f908f3bd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 662 µs (started: 2023-11-30 23:15:44 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cifar10 = datasets.CIFAR10(\n",
        "    './data', train=True, download=False,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7LgQLimUXl2",
        "outputId": "21189d65-5a65-44cc-cb2b-44b6b7041335"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 705 ms (started: 2023-11-30 23:15:45 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cifar10_val = datasets.CIFAR10(\n",
        "     './data', train=False, download=False,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXge3KZ0Ud2I",
        "outputId": "8550f8e9-6318-4b6a-ee94-e579e217c554"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 499 ms (started: 2023-11-30 23:15:47 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first_image, label = cifar10[0]\n",
        "print(first_image.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zGrIQDbdE0r",
        "outputId": "64b2c286-4b61-4ccd-b975-e0a646810fde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 32, 32])\n",
            "time: 7.62 ms (started: 2023-11-30 23:15:48 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(cifar10, batch_size=32, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(cifar10_val, batch_size=32, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnSjAIclhyxH",
        "outputId": "d3300d6b-0fe7-4ec8-c403-e041bf6f3c5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.18 ms (started: 2023-11-30 23:19:05 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(32 * 32 * 3, 512),\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(512, 10)\n",
        ").to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1oMEPlOWeyJ",
        "outputId": "b39aefc7-5664-4575-c435-f3cdd424f0f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 44.6 ms (started: 2023-11-30 23:34:06 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, test_loader, num_epochs=300, lr=0.001):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Testing the model\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        all_predicted = []\n",
        "        all_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in test_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "                all_predicted.extend(predicted.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        accuracy = correct / total\n",
        "\n",
        "        if epoch % 1 == 0:\n",
        "            print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}, Test Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "    # Classification Report\n",
        "    report = classification_report(all_labels, all_predicted)\n",
        "    print(\"Classification Report:\\n\", report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICZu-ov1cO7y",
        "outputId": "394e902e-e994-4141-f7c3-8a77063222b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.59 ms (started: 2023-11-30 23:34:07 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, train_loader, test_loader, num_epochs=300, lr=0.01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e5OZzeNhGqi",
        "outputId": "8b8bffa2-0146-4f4d-c744-ea55f9ab31e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300, Loss: 1.7398397800484606, Test Accuracy: 41.89%\n",
            "Epoch 2/300, Loss: 1.634406721675846, Test Accuracy: 43.21%\n",
            "Epoch 3/300, Loss: 1.5660125428258953, Test Accuracy: 45.81%\n",
            "Epoch 4/300, Loss: 1.5045548411645115, Test Accuracy: 45.98%\n",
            "Epoch 5/300, Loss: 1.4462770357089247, Test Accuracy: 46.90%\n",
            "Epoch 6/300, Loss: 1.393377955266473, Test Accuracy: 47.19%\n",
            "Epoch 7/300, Loss: 1.33971855736511, Test Accuracy: 46.97%\n",
            "Epoch 8/300, Loss: 1.286995179517408, Test Accuracy: 47.02%\n",
            "Epoch 9/300, Loss: 1.2365475362184637, Test Accuracy: 47.75%\n",
            "Epoch 10/300, Loss: 1.1836568696027525, Test Accuracy: 48.50%\n",
            "Epoch 11/300, Loss: 1.1335558970616708, Test Accuracy: 48.34%\n",
            "Epoch 12/300, Loss: 1.0809114643265938, Test Accuracy: 48.87%\n",
            "Epoch 13/300, Loss: 1.029821600467062, Test Accuracy: 47.75%\n",
            "Epoch 14/300, Loss: 0.9790819698774273, Test Accuracy: 48.79%\n",
            "Epoch 15/300, Loss: 0.9285842062224964, Test Accuracy: 47.34%\n",
            "Epoch 16/300, Loss: 0.8829675394986886, Test Accuracy: 46.96%\n",
            "Epoch 17/300, Loss: 0.8342071225341131, Test Accuracy: 47.62%\n",
            "Epoch 18/300, Loss: 0.7866293871852731, Test Accuracy: 47.83%\n",
            "Epoch 19/300, Loss: 0.7429452535820862, Test Accuracy: 46.97%\n",
            "Epoch 20/300, Loss: 0.6994615423892907, Test Accuracy: 47.29%\n",
            "Epoch 21/300, Loss: 0.6582873234250037, Test Accuracy: 47.12%\n",
            "Epoch 22/300, Loss: 0.6156003515421391, Test Accuracy: 46.59%\n",
            "Epoch 23/300, Loss: 0.576058319190032, Test Accuracy: 47.60%\n",
            "Epoch 24/300, Loss: 0.5407616428206231, Test Accuracy: 46.67%\n",
            "Epoch 25/300, Loss: 0.5076861263122302, Test Accuracy: 47.23%\n",
            "Epoch 26/300, Loss: 0.4707470684671585, Test Accuracy: 46.16%\n",
            "Epoch 27/300, Loss: 0.44034276058943855, Test Accuracy: 45.38%\n",
            "Epoch 28/300, Loss: 0.41059330893264545, Test Accuracy: 46.27%\n",
            "Epoch 29/300, Loss: 0.38243159379092684, Test Accuracy: 46.59%\n",
            "Epoch 30/300, Loss: 0.35291599211541036, Test Accuracy: 45.84%\n",
            "Epoch 31/300, Loss: 0.3289514998652122, Test Accuracy: 45.96%\n",
            "Epoch 32/300, Loss: 0.3074599751393458, Test Accuracy: 46.61%\n",
            "Epoch 33/300, Loss: 0.2830347623282797, Test Accuracy: 46.64%\n",
            "Epoch 34/300, Loss: 0.26218090246902853, Test Accuracy: 45.45%\n",
            "Epoch 35/300, Loss: 0.24230989192207883, Test Accuracy: 46.78%\n",
            "Epoch 36/300, Loss: 0.22173591471507773, Test Accuracy: 45.94%\n",
            "Epoch 37/300, Loss: 0.20716336343296812, Test Accuracy: 46.17%\n",
            "Epoch 38/300, Loss: 0.19081516282886782, Test Accuracy: 46.48%\n",
            "Epoch 39/300, Loss: 0.17715056288465428, Test Accuracy: 44.93%\n",
            "Epoch 40/300, Loss: 0.16391193526376918, Test Accuracy: 46.62%\n",
            "Epoch 41/300, Loss: 0.14942144049344655, Test Accuracy: 46.61%\n",
            "Epoch 42/300, Loss: 0.13989854885011396, Test Accuracy: 46.02%\n",
            "Epoch 43/300, Loss: 0.1304408330410738, Test Accuracy: 46.34%\n",
            "Epoch 44/300, Loss: 0.11800768332447445, Test Accuracy: 45.97%\n",
            "Epoch 45/300, Loss: 0.11279167318317422, Test Accuracy: 45.57%\n",
            "Epoch 46/300, Loss: 0.10118142898675347, Test Accuracy: 45.66%\n",
            "Epoch 47/300, Loss: 0.09466805634871173, Test Accuracy: 45.91%\n",
            "Epoch 48/300, Loss: 0.0892984937454597, Test Accuracy: 45.83%\n",
            "Epoch 49/300, Loss: 0.08218878695547047, Test Accuracy: 46.33%\n",
            "Epoch 50/300, Loss: 0.07644442150456282, Test Accuracy: 46.11%\n",
            "Epoch 51/300, Loss: 0.07192159039388463, Test Accuracy: 45.95%\n",
            "Epoch 52/300, Loss: 0.0668475516760151, Test Accuracy: 46.46%\n",
            "Epoch 53/300, Loss: 0.06279168648958702, Test Accuracy: 46.29%\n",
            "Epoch 54/300, Loss: 0.058618890116812324, Test Accuracy: 45.80%\n",
            "Epoch 55/300, Loss: 0.055183724996586754, Test Accuracy: 46.16%\n",
            "Epoch 56/300, Loss: 0.05113796172669528, Test Accuracy: 45.63%\n",
            "Epoch 57/300, Loss: 0.04905187973534535, Test Accuracy: 46.14%\n",
            "Epoch 58/300, Loss: 0.046791759963723534, Test Accuracy: 46.23%\n",
            "Epoch 59/300, Loss: 0.043864647502714786, Test Accuracy: 46.06%\n",
            "Epoch 60/300, Loss: 0.04174053937706784, Test Accuracy: 46.32%\n",
            "Epoch 61/300, Loss: 0.039341191309536984, Test Accuracy: 46.03%\n",
            "Epoch 62/300, Loss: 0.03715188138160714, Test Accuracy: 46.09%\n",
            "Epoch 63/300, Loss: 0.0358054870352273, Test Accuracy: 46.06%\n",
            "Epoch 64/300, Loss: 0.03437384671066254, Test Accuracy: 46.35%\n",
            "Epoch 65/300, Loss: 0.03303456248778681, Test Accuracy: 45.66%\n",
            "Epoch 66/300, Loss: 0.03215892369407858, Test Accuracy: 45.89%\n",
            "Epoch 67/300, Loss: 0.030470268156734592, Test Accuracy: 46.02%\n",
            "Epoch 68/300, Loss: 0.028826122596426147, Test Accuracy: 45.96%\n",
            "Epoch 69/300, Loss: 0.027324613823090045, Test Accuracy: 46.04%\n",
            "Epoch 70/300, Loss: 0.02664047237235388, Test Accuracy: 46.14%\n",
            "Epoch 71/300, Loss: 0.025808130694232687, Test Accuracy: 45.93%\n",
            "Epoch 72/300, Loss: 0.02507488561707167, Test Accuracy: 46.02%\n",
            "Epoch 73/300, Loss: 0.024339277089304712, Test Accuracy: 45.99%\n",
            "Epoch 74/300, Loss: 0.023460932827351455, Test Accuracy: 46.14%\n",
            "Epoch 75/300, Loss: 0.022617636319972045, Test Accuracy: 46.02%\n",
            "Epoch 76/300, Loss: 0.021767551315947174, Test Accuracy: 46.12%\n",
            "Epoch 77/300, Loss: 0.02133085502350914, Test Accuracy: 46.01%\n",
            "Epoch 78/300, Loss: 0.020415819055798225, Test Accuracy: 45.96%\n",
            "Epoch 79/300, Loss: 0.019788710524400153, Test Accuracy: 45.92%\n",
            "Epoch 80/300, Loss: 0.019675272075377132, Test Accuracy: 45.96%\n",
            "Epoch 81/300, Loss: 0.018747400350616058, Test Accuracy: 45.88%\n",
            "Epoch 82/300, Loss: 0.018541271687483492, Test Accuracy: 45.04%\n",
            "Epoch 83/300, Loss: 0.018239852037430955, Test Accuracy: 45.97%\n",
            "Epoch 84/300, Loss: 0.017389990109294862, Test Accuracy: 45.86%\n",
            "Epoch 85/300, Loss: 0.01693366625645959, Test Accuracy: 45.87%\n",
            "Epoch 86/300, Loss: 0.016532093232291406, Test Accuracy: 46.00%\n",
            "Epoch 87/300, Loss: 0.01613064377043713, Test Accuracy: 46.09%\n",
            "Epoch 88/300, Loss: 0.015746426199260748, Test Accuracy: 45.98%\n",
            "Epoch 89/300, Loss: 0.01570569513388269, Test Accuracy: 46.04%\n",
            "Epoch 90/300, Loss: 0.015223961950637882, Test Accuracy: 46.07%\n",
            "Epoch 91/300, Loss: 0.014909831890437134, Test Accuracy: 45.95%\n",
            "Epoch 92/300, Loss: 0.01451954095381874, Test Accuracy: 45.71%\n",
            "Epoch 93/300, Loss: 0.01414921117192152, Test Accuracy: 45.92%\n",
            "Epoch 94/300, Loss: 0.014054080586694538, Test Accuracy: 45.73%\n",
            "Epoch 95/300, Loss: 0.013670801470486384, Test Accuracy: 45.73%\n",
            "Epoch 96/300, Loss: 0.013459231574874865, Test Accuracy: 45.98%\n",
            "Epoch 97/300, Loss: 0.013084702224125675, Test Accuracy: 46.06%\n",
            "Epoch 98/300, Loss: 0.012957961286906145, Test Accuracy: 46.09%\n",
            "Epoch 99/300, Loss: 0.012580455352938946, Test Accuracy: 46.10%\n",
            "Epoch 100/300, Loss: 0.01235194606599246, Test Accuracy: 46.06%\n",
            "Epoch 101/300, Loss: 0.012134836762321258, Test Accuracy: 46.10%\n",
            "Epoch 102/300, Loss: 0.011929219552886006, Test Accuracy: 45.77%\n",
            "Epoch 103/300, Loss: 0.01181220701107337, Test Accuracy: 45.78%\n",
            "Epoch 104/300, Loss: 0.011532240568988517, Test Accuracy: 45.95%\n",
            "Epoch 105/300, Loss: 0.011325615407840628, Test Accuracy: 46.00%\n",
            "Epoch 106/300, Loss: 0.011255013338461165, Test Accuracy: 46.08%\n",
            "Epoch 107/300, Loss: 0.011015685950003693, Test Accuracy: 45.94%\n",
            "Epoch 108/300, Loss: 0.010789697439548628, Test Accuracy: 45.81%\n",
            "Epoch 109/300, Loss: 0.010628545356191033, Test Accuracy: 45.88%\n",
            "Epoch 110/300, Loss: 0.010409894632324529, Test Accuracy: 45.94%\n",
            "Epoch 111/300, Loss: 0.010307657743624804, Test Accuracy: 46.01%\n",
            "Epoch 112/300, Loss: 0.010228422236815334, Test Accuracy: 45.94%\n",
            "Epoch 113/300, Loss: 0.010008778310156239, Test Accuracy: 45.71%\n",
            "Epoch 114/300, Loss: 0.00982312906577573, Test Accuracy: 45.90%\n",
            "Epoch 115/300, Loss: 0.009655637840870875, Test Accuracy: 45.97%\n",
            "Epoch 116/300, Loss: 0.009531338487335278, Test Accuracy: 45.94%\n",
            "Epoch 117/300, Loss: 0.009401967007755013, Test Accuracy: 45.97%\n",
            "Epoch 118/300, Loss: 0.009252358276530462, Test Accuracy: 46.02%\n",
            "Epoch 119/300, Loss: 0.00912051437683618, Test Accuracy: 46.00%\n",
            "Epoch 120/300, Loss: 0.009049014239890771, Test Accuracy: 45.96%\n",
            "Epoch 121/300, Loss: 0.008911560317269042, Test Accuracy: 46.02%\n",
            "Epoch 122/300, Loss: 0.008779681728043316, Test Accuracy: 45.82%\n",
            "Epoch 123/300, Loss: 0.00866087019009729, Test Accuracy: 45.84%\n",
            "Epoch 124/300, Loss: 0.008531520523903123, Test Accuracy: 45.81%\n",
            "Epoch 125/300, Loss: 0.008433672457680784, Test Accuracy: 45.83%\n",
            "Epoch 126/300, Loss: 0.008315954632968931, Test Accuracy: 46.06%\n",
            "Epoch 127/300, Loss: 0.008237582723766812, Test Accuracy: 45.97%\n",
            "Epoch 128/300, Loss: 0.008147244852170901, Test Accuracy: 45.84%\n",
            "Epoch 129/300, Loss: 0.008022824941222065, Test Accuracy: 45.81%\n",
            "Epoch 130/300, Loss: 0.007925619044408479, Test Accuracy: 46.05%\n",
            "Epoch 131/300, Loss: 0.007851372534166056, Test Accuracy: 46.08%\n",
            "Epoch 132/300, Loss: 0.0077666730896444065, Test Accuracy: 45.81%\n",
            "Epoch 133/300, Loss: 0.007641070154129086, Test Accuracy: 45.81%\n",
            "Epoch 134/300, Loss: 0.00754684237799037, Test Accuracy: 46.07%\n",
            "Epoch 135/300, Loss: 0.007504707040689452, Test Accuracy: 45.80%\n",
            "Epoch 136/300, Loss: 0.007392329271401321, Test Accuracy: 45.94%\n",
            "Epoch 137/300, Loss: 0.007316647835137824, Test Accuracy: 45.99%\n",
            "Epoch 138/300, Loss: 0.007219641217669938, Test Accuracy: 45.84%\n",
            "Epoch 139/300, Loss: 0.00715271535869366, Test Accuracy: 45.78%\n",
            "Epoch 140/300, Loss: 0.007077719439601648, Test Accuracy: 45.88%\n",
            "Epoch 141/300, Loss: 0.007090717438347423, Test Accuracy: 45.92%\n",
            "Epoch 142/300, Loss: 0.006923595439494896, Test Accuracy: 45.93%\n",
            "Epoch 143/300, Loss: 0.006845484640996281, Test Accuracy: 45.90%\n",
            "Epoch 144/300, Loss: 0.006767179527524346, Test Accuracy: 45.97%\n",
            "Epoch 145/300, Loss: 0.006720257040395646, Test Accuracy: 45.95%\n",
            "Epoch 146/300, Loss: 0.006626686942599766, Test Accuracy: 45.87%\n",
            "Epoch 147/300, Loss: 0.006559657915814119, Test Accuracy: 45.87%\n",
            "Epoch 148/300, Loss: 0.0065096716476355275, Test Accuracy: 45.75%\n",
            "Epoch 149/300, Loss: 0.006444778895632424, Test Accuracy: 45.85%\n",
            "Epoch 150/300, Loss: 0.006363591377075788, Test Accuracy: 45.74%\n",
            "Epoch 151/300, Loss: 0.006300557395222854, Test Accuracy: 45.90%\n",
            "Epoch 152/300, Loss: 0.006251943381252965, Test Accuracy: 45.72%\n",
            "Epoch 153/300, Loss: 0.006178737973903978, Test Accuracy: 45.81%\n",
            "Epoch 154/300, Loss: 0.006138812719146534, Test Accuracy: 45.98%\n",
            "Epoch 155/300, Loss: 0.006072444313486427, Test Accuracy: 45.74%\n",
            "Epoch 156/300, Loss: 0.0060099446998583776, Test Accuracy: 45.98%\n",
            "Epoch 157/300, Loss: 0.005952370739902441, Test Accuracy: 45.93%\n",
            "Epoch 158/300, Loss: 0.00590042026385174, Test Accuracy: 45.97%\n",
            "Epoch 159/300, Loss: 0.005872168786012194, Test Accuracy: 45.96%\n",
            "Epoch 160/300, Loss: 0.005792519733397932, Test Accuracy: 45.75%\n",
            "Epoch 161/300, Loss: 0.005733146927613224, Test Accuracy: 45.86%\n",
            "Epoch 162/300, Loss: 0.005687506650756242, Test Accuracy: 45.85%\n",
            "Epoch 163/300, Loss: 0.005651247261600927, Test Accuracy: 45.77%\n",
            "Epoch 164/300, Loss: 0.005586005682518953, Test Accuracy: 45.95%\n",
            "Epoch 165/300, Loss: 0.005540961323404876, Test Accuracy: 45.92%\n",
            "Epoch 166/300, Loss: 0.0054912050781975325, Test Accuracy: 45.87%\n",
            "Epoch 167/300, Loss: 0.005444516041402491, Test Accuracy: 45.89%\n",
            "Epoch 168/300, Loss: 0.005403446132955942, Test Accuracy: 45.86%\n",
            "Epoch 169/300, Loss: 0.0053567526634408355, Test Accuracy: 45.83%\n",
            "Epoch 170/300, Loss: 0.005310019907366987, Test Accuracy: 45.82%\n",
            "Epoch 171/300, Loss: 0.00525276216687855, Test Accuracy: 45.93%\n",
            "Epoch 172/300, Loss: 0.005213369821244165, Test Accuracy: 45.88%\n",
            "Epoch 173/300, Loss: 0.005179836719683583, Test Accuracy: 45.90%\n",
            "Epoch 174/300, Loss: 0.00513962398834946, Test Accuracy: 45.91%\n",
            "Epoch 175/300, Loss: 0.005101041505899774, Test Accuracy: 45.88%\n",
            "Epoch 176/300, Loss: 0.005054270929221352, Test Accuracy: 45.84%\n",
            "Epoch 177/300, Loss: 0.005017508355059297, Test Accuracy: 45.73%\n",
            "Epoch 178/300, Loss: 0.004969139708389581, Test Accuracy: 45.85%\n",
            "Epoch 179/300, Loss: 0.004936716749892354, Test Accuracy: 45.91%\n",
            "Epoch 180/300, Loss: 0.004895985242091381, Test Accuracy: 45.97%\n",
            "Epoch 181/300, Loss: 0.00484919499874625, Test Accuracy: 45.87%\n",
            "Epoch 182/300, Loss: 0.004817054410490683, Test Accuracy: 45.75%\n",
            "Epoch 183/300, Loss: 0.004775398669905021, Test Accuracy: 45.90%\n",
            "Epoch 184/300, Loss: 0.004745691811954287, Test Accuracy: 45.69%\n",
            "Epoch 185/300, Loss: 0.004704746547299875, Test Accuracy: 45.68%\n",
            "Epoch 186/300, Loss: 0.0046739634393070245, Test Accuracy: 45.92%\n",
            "Epoch 187/300, Loss: 0.004644829999138282, Test Accuracy: 45.65%\n",
            "Epoch 188/300, Loss: 0.0046043135160228725, Test Accuracy: 45.85%\n",
            "Epoch 189/300, Loss: 0.004570262356448539, Test Accuracy: 45.66%\n",
            "Epoch 190/300, Loss: 0.004541466671315642, Test Accuracy: 45.69%\n",
            "Epoch 191/300, Loss: 0.004500113348837082, Test Accuracy: 45.71%\n",
            "Epoch 192/300, Loss: 0.004471920339941206, Test Accuracy: 45.84%\n",
            "Epoch 193/300, Loss: 0.004437369223855679, Test Accuracy: 45.84%\n",
            "Epoch 194/300, Loss: 0.004410071136407264, Test Accuracy: 45.87%\n",
            "Epoch 195/300, Loss: 0.004375665821909657, Test Accuracy: 45.80%\n",
            "Epoch 196/300, Loss: 0.004341012222206152, Test Accuracy: 45.69%\n",
            "Epoch 197/300, Loss: 0.004317988382660744, Test Accuracy: 45.74%\n",
            "Epoch 198/300, Loss: 0.004288743131347739, Test Accuracy: 45.79%\n",
            "Epoch 199/300, Loss: 0.004256024923484226, Test Accuracy: 45.79%\n",
            "Epoch 200/300, Loss: 0.004228431621527088, Test Accuracy: 45.75%\n",
            "Epoch 201/300, Loss: 0.004208186066781558, Test Accuracy: 45.84%\n",
            "Epoch 202/300, Loss: 0.0041686894823615315, Test Accuracy: 45.87%\n",
            "Epoch 203/300, Loss: 0.004149320587797075, Test Accuracy: 45.81%\n",
            "Epoch 204/300, Loss: 0.004115974509573744, Test Accuracy: 45.64%\n",
            "Epoch 205/300, Loss: 0.004088752895596026, Test Accuracy: 45.75%\n",
            "Epoch 206/300, Loss: 0.004062915516848022, Test Accuracy: 45.74%\n",
            "Epoch 207/300, Loss: 0.0040355828085405394, Test Accuracy: 45.76%\n",
            "Epoch 208/300, Loss: 0.00401132908647955, Test Accuracy: 45.81%\n",
            "Epoch 209/300, Loss: 0.00398214256755295, Test Accuracy: 45.74%\n",
            "Epoch 210/300, Loss: 0.003953710187230109, Test Accuracy: 45.78%\n",
            "Epoch 211/300, Loss: 0.003929035707572934, Test Accuracy: 45.80%\n",
            "Epoch 212/300, Loss: 0.003908507072847034, Test Accuracy: 45.67%\n",
            "Epoch 213/300, Loss: 0.003877054770630251, Test Accuracy: 45.73%\n",
            "Epoch 214/300, Loss: 0.0038571496852670612, Test Accuracy: 45.88%\n",
            "Epoch 215/300, Loss: 0.0038310212776737, Test Accuracy: 45.88%\n",
            "Epoch 216/300, Loss: 0.0038113118720169985, Test Accuracy: 45.87%\n",
            "Epoch 217/300, Loss: 0.0037857962281265018, Test Accuracy: 45.81%\n",
            "Epoch 218/300, Loss: 0.0037624528211489634, Test Accuracy: 45.76%\n",
            "Epoch 219/300, Loss: 0.0037412279064576986, Test Accuracy: 45.76%\n",
            "Epoch 220/300, Loss: 0.00371136761251694, Test Accuracy: 45.70%\n",
            "Epoch 221/300, Loss: 0.0036936521861447177, Test Accuracy: 45.81%\n",
            "Epoch 222/300, Loss: 0.003666829641730246, Test Accuracy: 45.78%\n",
            "Epoch 223/300, Loss: 0.0036486858445870965, Test Accuracy: 45.84%\n",
            "Epoch 224/300, Loss: 0.003629487482529975, Test Accuracy: 45.68%\n",
            "Epoch 225/300, Loss: 0.0036086827111820752, Test Accuracy: 45.78%\n",
            "Epoch 226/300, Loss: 0.003582780181712716, Test Accuracy: 45.66%\n",
            "Epoch 227/300, Loss: 0.0035641106059035896, Test Accuracy: 45.77%\n",
            "Epoch 228/300, Loss: 0.0035413711537206002, Test Accuracy: 45.67%\n",
            "Epoch 229/300, Loss: 0.0035261159959521504, Test Accuracy: 45.80%\n",
            "Epoch 230/300, Loss: 0.0035056009328097667, Test Accuracy: 45.69%\n",
            "Epoch 231/300, Loss: 0.0034849155717037775, Test Accuracy: 45.77%\n",
            "Epoch 232/300, Loss: 0.003463819136179302, Test Accuracy: 45.70%\n",
            "Epoch 233/300, Loss: 0.0034398287796145468, Test Accuracy: 45.84%\n",
            "Epoch 234/300, Loss: 0.003423698400656716, Test Accuracy: 45.76%\n",
            "Epoch 235/300, Loss: 0.0034045296846588052, Test Accuracy: 45.68%\n",
            "Epoch 236/300, Loss: 0.003384860265840343, Test Accuracy: 45.71%\n",
            "Epoch 237/300, Loss: 0.0033651118156168267, Test Accuracy: 45.75%\n",
            "Epoch 238/300, Loss: 0.0033505360599755, Test Accuracy: 45.66%\n",
            "Epoch 239/300, Loss: 0.0033265158270532774, Test Accuracy: 45.76%\n",
            "Epoch 240/300, Loss: 0.0033104051013554013, Test Accuracy: 45.74%\n",
            "Epoch 241/300, Loss: 0.0032903750797838535, Test Accuracy: 45.78%\n",
            "Epoch 242/300, Loss: 0.0032757957116924157, Test Accuracy: 45.67%\n",
            "Epoch 243/300, Loss: 0.0032574206476546083, Test Accuracy: 45.73%\n",
            "Epoch 244/300, Loss: 0.003239659191870744, Test Accuracy: 45.87%\n",
            "Epoch 245/300, Loss: 0.0032218377322187353, Test Accuracy: 45.70%\n",
            "Epoch 246/300, Loss: 0.0032090632359199917, Test Accuracy: 45.71%\n",
            "Epoch 247/300, Loss: 0.0031857306653990036, Test Accuracy: 45.81%\n",
            "Epoch 248/300, Loss: 0.003171215737768838, Test Accuracy: 45.73%\n",
            "Epoch 249/300, Loss: 0.0031545296162712464, Test Accuracy: 45.74%\n",
            "Epoch 250/300, Loss: 0.0031412176347515824, Test Accuracy: 45.65%\n",
            "Epoch 251/300, Loss: 0.0031222789689108387, Test Accuracy: 45.69%\n",
            "Epoch 252/300, Loss: 0.0031041359554669955, Test Accuracy: 45.86%\n",
            "Epoch 253/300, Loss: 0.0030883212527796455, Test Accuracy: 45.67%\n",
            "Epoch 254/300, Loss: 0.0030730105748087862, Test Accuracy: 45.78%\n",
            "Epoch 255/300, Loss: 0.003056519607249445, Test Accuracy: 45.86%\n",
            "Epoch 256/300, Loss: 0.003042435181840792, Test Accuracy: 45.74%\n",
            "Epoch 257/300, Loss: 0.003029146700276995, Test Accuracy: 45.75%\n",
            "Epoch 258/300, Loss: 0.0030111415582510593, Test Accuracy: 45.73%\n",
            "Epoch 259/300, Loss: 0.0029976938457763917, Test Accuracy: 45.83%\n",
            "Epoch 260/300, Loss: 0.0029861513365558225, Test Accuracy: 45.68%\n",
            "Epoch 261/300, Loss: 0.0029698501485390964, Test Accuracy: 45.91%\n",
            "Epoch 262/300, Loss: 0.002951636516354425, Test Accuracy: 45.77%\n",
            "Epoch 263/300, Loss: 0.0029385944785042567, Test Accuracy: 45.71%\n",
            "Epoch 264/300, Loss: 0.0029263722210388417, Test Accuracy: 45.79%\n",
            "Epoch 265/300, Loss: 0.0029107825143855023, Test Accuracy: 45.80%\n",
            "Epoch 266/300, Loss: 0.0028951929166992877, Test Accuracy: 45.68%\n",
            "Epoch 267/300, Loss: 0.0028814193593029477, Test Accuracy: 45.79%\n",
            "Epoch 268/300, Loss: 0.002867730286136813, Test Accuracy: 45.78%\n",
            "Epoch 269/300, Loss: 0.002853699518806794, Test Accuracy: 45.67%\n",
            "Epoch 270/300, Loss: 0.0028404776393945353, Test Accuracy: 45.64%\n",
            "Epoch 271/300, Loss: 0.002827458183137522, Test Accuracy: 45.65%\n",
            "Epoch 272/300, Loss: 0.0028141656358263343, Test Accuracy: 45.77%\n",
            "Epoch 273/300, Loss: 0.002797279441154187, Test Accuracy: 45.75%\n",
            "Epoch 274/300, Loss: 0.0027859313705470116, Test Accuracy: 45.81%\n",
            "Epoch 275/300, Loss: 0.002773599991853744, Test Accuracy: 45.72%\n",
            "Epoch 276/300, Loss: 0.002760119458078928, Test Accuracy: 45.68%\n",
            "Epoch 277/300, Loss: 0.0027462949631324543, Test Accuracy: 45.65%\n",
            "Epoch 278/300, Loss: 0.002735559340945957, Test Accuracy: 45.80%\n",
            "Epoch 279/300, Loss: 0.002722465788831747, Test Accuracy: 45.82%\n",
            "Epoch 280/300, Loss: 0.0027100125956930035, Test Accuracy: 45.71%\n",
            "Epoch 281/300, Loss: 0.002696790963560891, Test Accuracy: 45.75%\n",
            "Epoch 282/300, Loss: 0.002688020471556759, Test Accuracy: 45.83%\n",
            "Epoch 283/300, Loss: 0.0026752151661628165, Test Accuracy: 45.72%\n",
            "Epoch 284/300, Loss: 0.0026620642702296013, Test Accuracy: 45.76%\n",
            "Epoch 285/300, Loss: 0.0026485080489178528, Test Accuracy: 45.67%\n",
            "Epoch 286/300, Loss: 0.0026380574858466776, Test Accuracy: 45.74%\n",
            "Epoch 287/300, Loss: 0.002625837715110853, Test Accuracy: 45.69%\n",
            "Epoch 288/300, Loss: 0.002614506280796885, Test Accuracy: 45.76%\n",
            "Epoch 289/300, Loss: 0.0026021390453651928, Test Accuracy: 45.61%\n",
            "Epoch 290/300, Loss: 0.002591549860470245, Test Accuracy: 45.77%\n",
            "Epoch 291/300, Loss: 0.002581711703141578, Test Accuracy: 45.74%\n",
            "Epoch 292/300, Loss: 0.002569923296830571, Test Accuracy: 45.69%\n",
            "Epoch 293/300, Loss: 0.0025575494827042434, Test Accuracy: 45.67%\n",
            "Epoch 294/300, Loss: 0.0025463292910136467, Test Accuracy: 45.70%\n",
            "Epoch 295/300, Loss: 0.00253515779250793, Test Accuracy: 45.68%\n",
            "Epoch 296/300, Loss: 0.0025253969344315825, Test Accuracy: 45.70%\n",
            "Epoch 297/300, Loss: 0.0025140258227519677, Test Accuracy: 45.80%\n",
            "Epoch 298/300, Loss: 0.0025043091189291423, Test Accuracy: 45.72%\n",
            "Epoch 299/300, Loss: 0.002492132710480034, Test Accuracy: 45.66%\n",
            "Epoch 300/300, Loss: 0.0024821913834799482, Test Accuracy: 45.74%\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.53      0.53      1000\n",
            "           1       0.59      0.53      0.56      1000\n",
            "           2       0.32      0.36      0.34      1000\n",
            "           3       0.31      0.30      0.30      1000\n",
            "           4       0.40      0.40      0.40      1000\n",
            "           5       0.35      0.34      0.35      1000\n",
            "           6       0.48      0.50      0.49      1000\n",
            "           7       0.51      0.47      0.49      1000\n",
            "           8       0.59      0.62      0.61      1000\n",
            "           9       0.53      0.50      0.52      1000\n",
            "\n",
            "    accuracy                           0.46     10000\n",
            "   macro avg       0.46      0.46      0.46     10000\n",
            "weighted avg       0.46      0.46      0.46     10000\n",
            "\n",
            "time: 1h 33min 32s (started: 2023-11-30 23:35:37 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(32 * 32 * 3, 512),\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(512, 256),\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(256, 128),\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(128, 10)\n",
        ").to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwT6edYguxUz",
        "outputId": "4864450b-cca2-4649-85f0-f358a4ae44ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 31.5 ms (started: 2023-12-01 01:09:11 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model2, train_loader, test_loader, num_epochs=300, lr=0.01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tf4CmrcvQvg",
        "outputId": "a113901d-207d-47ba-800b-5bb3edfd2a95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300, Loss: 1.8508661996075075, Test Accuracy: 39.19%\n",
            "Epoch 2/300, Loss: 1.6860174748352987, Test Accuracy: 42.09%\n",
            "Epoch 3/300, Loss: 1.613621175937445, Test Accuracy: 43.42%\n",
            "Epoch 4/300, Loss: 1.5521392714725575, Test Accuracy: 45.22%\n",
            "Epoch 5/300, Loss: 1.4946926155306937, Test Accuracy: 46.36%\n",
            "Epoch 6/300, Loss: 1.4416150330581958, Test Accuracy: 47.50%\n",
            "Epoch 7/300, Loss: 1.3840028547889822, Test Accuracy: 47.84%\n",
            "Epoch 8/300, Loss: 1.3247861227238704, Test Accuracy: 48.54%\n",
            "Epoch 9/300, Loss: 1.2697526247014774, Test Accuracy: 48.28%\n",
            "Epoch 10/300, Loss: 1.2086391765493196, Test Accuracy: 48.70%\n",
            "Epoch 11/300, Loss: 1.1492945738732625, Test Accuracy: 47.45%\n",
            "Epoch 12/300, Loss: 1.0891687711384994, Test Accuracy: 46.37%\n",
            "Epoch 13/300, Loss: 1.0271452304192712, Test Accuracy: 48.22%\n",
            "Epoch 14/300, Loss: 0.9693194204465899, Test Accuracy: 47.59%\n",
            "Epoch 15/300, Loss: 0.9086546413385936, Test Accuracy: 47.31%\n",
            "Epoch 16/300, Loss: 0.8466312264450376, Test Accuracy: 47.46%\n",
            "Epoch 17/300, Loss: 0.7908831752040641, Test Accuracy: 47.67%\n",
            "Epoch 18/300, Loss: 0.7319355071811285, Test Accuracy: 47.46%\n",
            "Epoch 19/300, Loss: 0.6816775844368657, Test Accuracy: 42.94%\n",
            "Epoch 20/300, Loss: 0.6291214101450304, Test Accuracy: 47.30%\n",
            "Epoch 21/300, Loss: 0.5776757993190165, Test Accuracy: 46.95%\n",
            "Epoch 22/300, Loss: 0.5260614533494545, Test Accuracy: 47.35%\n",
            "Epoch 23/300, Loss: 0.4826986345909989, Test Accuracy: 46.62%\n",
            "Epoch 24/300, Loss: 0.43963031501283417, Test Accuracy: 46.03%\n",
            "Epoch 25/300, Loss: 0.39834614331647517, Test Accuracy: 46.14%\n",
            "Epoch 26/300, Loss: 0.3612439011534055, Test Accuracy: 46.58%\n",
            "Epoch 27/300, Loss: 0.33189043381936034, Test Accuracy: 45.29%\n",
            "Epoch 28/300, Loss: 0.29755125867389975, Test Accuracy: 45.50%\n",
            "Epoch 29/300, Loss: 0.26695558552940685, Test Accuracy: 44.70%\n",
            "Epoch 30/300, Loss: 0.24388459810459187, Test Accuracy: 45.75%\n",
            "Epoch 31/300, Loss: 0.21731720005787114, Test Accuracy: 44.88%\n",
            "Epoch 32/300, Loss: 0.19447753036434043, Test Accuracy: 46.43%\n",
            "Epoch 33/300, Loss: 0.17500968521755245, Test Accuracy: 46.02%\n",
            "Epoch 34/300, Loss: 0.1507635939334801, Test Accuracy: 45.90%\n",
            "Epoch 35/300, Loss: 0.1357290128797712, Test Accuracy: 46.65%\n",
            "Epoch 36/300, Loss: 0.11464614706365385, Test Accuracy: 46.36%\n",
            "Epoch 37/300, Loss: 0.11284691040593027, Test Accuracy: 45.67%\n",
            "Epoch 38/300, Loss: 0.10932873475936766, Test Accuracy: 45.92%\n",
            "Epoch 39/300, Loss: 0.0917809064037054, Test Accuracy: 45.91%\n",
            "Epoch 40/300, Loss: 0.07762084526479988, Test Accuracy: 46.78%\n",
            "Epoch 41/300, Loss: 0.05740675681270063, Test Accuracy: 45.03%\n",
            "Epoch 42/300, Loss: 0.050848118441569085, Test Accuracy: 46.35%\n",
            "Epoch 43/300, Loss: 0.04762253666061834, Test Accuracy: 46.85%\n",
            "Epoch 44/300, Loss: 0.03185839298188982, Test Accuracy: 45.51%\n",
            "Epoch 45/300, Loss: 0.03817923784137406, Test Accuracy: 46.72%\n",
            "Epoch 46/300, Loss: 0.020090525265263486, Test Accuracy: 46.82%\n",
            "Epoch 47/300, Loss: 0.016897133556304837, Test Accuracy: 46.29%\n",
            "Epoch 48/300, Loss: 0.009753854824641216, Test Accuracy: 46.77%\n",
            "Epoch 49/300, Loss: 0.008214393182093384, Test Accuracy: 46.62%\n",
            "Epoch 50/300, Loss: 0.0061438853089159605, Test Accuracy: 47.02%\n",
            "Epoch 51/300, Loss: 0.003849642917369948, Test Accuracy: 47.24%\n",
            "Epoch 52/300, Loss: 0.003080342347983638, Test Accuracy: 47.23%\n",
            "Epoch 53/300, Loss: 0.0028845924918044666, Test Accuracy: 47.30%\n",
            "Epoch 54/300, Loss: 0.0025342373207276445, Test Accuracy: 47.27%\n",
            "Epoch 55/300, Loss: 0.0023630462502044767, Test Accuracy: 47.26%\n",
            "Epoch 56/300, Loss: 0.002232571449662575, Test Accuracy: 47.43%\n",
            "Epoch 57/300, Loss: 0.0020645581989031303, Test Accuracy: 47.24%\n",
            "Epoch 58/300, Loss: 0.001984162018002772, Test Accuracy: 47.26%\n",
            "Epoch 59/300, Loss: 0.0019155306724762343, Test Accuracy: 47.28%\n",
            "Epoch 60/300, Loss: 0.0017719279411205664, Test Accuracy: 47.10%\n",
            "Epoch 61/300, Loss: 0.0017000840572695118, Test Accuracy: 47.17%\n",
            "Epoch 62/300, Loss: 0.0016298419475657907, Test Accuracy: 47.07%\n",
            "Epoch 63/300, Loss: 0.0015633322358633715, Test Accuracy: 47.08%\n",
            "Epoch 64/300, Loss: 0.0015075234382513729, Test Accuracy: 47.17%\n",
            "Epoch 65/300, Loss: 0.001458973742890251, Test Accuracy: 47.28%\n",
            "Epoch 66/300, Loss: 0.0014073682040974477, Test Accuracy: 47.11%\n",
            "Epoch 67/300, Loss: 0.0013588805309355603, Test Accuracy: 47.08%\n",
            "Epoch 68/300, Loss: 0.0013117012525549645, Test Accuracy: 47.01%\n",
            "Epoch 69/300, Loss: 0.0012768937178694666, Test Accuracy: 47.13%\n",
            "Epoch 70/300, Loss: 0.001242259826579817, Test Accuracy: 47.03%\n",
            "Epoch 71/300, Loss: 0.0012052109026415923, Test Accuracy: 47.18%\n",
            "Epoch 72/300, Loss: 0.001173113909447524, Test Accuracy: 47.04%\n",
            "Epoch 73/300, Loss: 0.0011402290310413932, Test Accuracy: 47.09%\n",
            "Epoch 74/300, Loss: 0.0011084572235476858, Test Accuracy: 47.02%\n",
            "Epoch 75/300, Loss: 0.001082275503416178, Test Accuracy: 47.13%\n",
            "Epoch 76/300, Loss: 0.0010578795606556444, Test Accuracy: 47.14%\n",
            "Epoch 77/300, Loss: 0.0010313452302079923, Test Accuracy: 47.04%\n",
            "Epoch 78/300, Loss: 0.001008644839517846, Test Accuracy: 47.07%\n",
            "Epoch 79/300, Loss: 0.0009848191287964094, Test Accuracy: 47.06%\n",
            "Epoch 80/300, Loss: 0.0009622855316558573, Test Accuracy: 47.11%\n",
            "Epoch 81/300, Loss: 0.0009417004746763883, Test Accuracy: 46.99%\n",
            "Epoch 82/300, Loss: 0.0009215571707740524, Test Accuracy: 47.10%\n",
            "Epoch 83/300, Loss: 0.0009027488080146219, Test Accuracy: 47.09%\n",
            "Epoch 84/300, Loss: 0.0008834403350504481, Test Accuracy: 47.08%\n",
            "Epoch 85/300, Loss: 0.0008667477990909684, Test Accuracy: 47.00%\n",
            "Epoch 86/300, Loss: 0.0008519336706583322, Test Accuracy: 47.11%\n",
            "Epoch 87/300, Loss: 0.0008331190912238896, Test Accuracy: 47.00%\n",
            "Epoch 88/300, Loss: 0.0008192677651526035, Test Accuracy: 46.98%\n",
            "Epoch 89/300, Loss: 0.0008022403849872164, Test Accuracy: 47.08%\n",
            "Epoch 90/300, Loss: 0.0007877244889983158, Test Accuracy: 47.14%\n",
            "Epoch 91/300, Loss: 0.0007754177113651446, Test Accuracy: 46.98%\n",
            "Epoch 92/300, Loss: 0.0007618390248755622, Test Accuracy: 47.04%\n",
            "Epoch 93/300, Loss: 0.0007480116704730907, Test Accuracy: 47.03%\n",
            "Epoch 94/300, Loss: 0.0007358523977001901, Test Accuracy: 46.99%\n",
            "Epoch 95/300, Loss: 0.0007231663332692564, Test Accuracy: 46.98%\n",
            "Epoch 96/300, Loss: 0.0007116696886875877, Test Accuracy: 47.05%\n",
            "Epoch 97/300, Loss: 0.0007006888844096504, Test Accuracy: 46.97%\n",
            "Epoch 98/300, Loss: 0.0006891109750158334, Test Accuracy: 47.01%\n",
            "Epoch 99/300, Loss: 0.0006781603221479751, Test Accuracy: 47.02%\n",
            "Epoch 100/300, Loss: 0.0006677708779307504, Test Accuracy: 47.06%\n",
            "Epoch 101/300, Loss: 0.000658145261220786, Test Accuracy: 46.99%\n",
            "Epoch 102/300, Loss: 0.0006478082311029235, Test Accuracy: 46.94%\n",
            "Epoch 103/300, Loss: 0.0006391287431828749, Test Accuracy: 47.00%\n",
            "Epoch 104/300, Loss: 0.0006284959538975613, Test Accuracy: 46.94%\n",
            "Epoch 105/300, Loss: 0.0006211079030014069, Test Accuracy: 46.94%\n",
            "Epoch 106/300, Loss: 0.0006117494311705065, Test Accuracy: 47.02%\n",
            "Epoch 107/300, Loss: 0.0006033560783137232, Test Accuracy: 46.90%\n",
            "Epoch 108/300, Loss: 0.0005951917828066646, Test Accuracy: 46.92%\n",
            "Epoch 109/300, Loss: 0.0005871776419118826, Test Accuracy: 46.96%\n",
            "Epoch 110/300, Loss: 0.0005791422776771818, Test Accuracy: 47.03%\n",
            "Epoch 111/300, Loss: 0.0005721053681078636, Test Accuracy: 46.96%\n",
            "Epoch 112/300, Loss: 0.0005639181898211761, Test Accuracy: 46.96%\n",
            "Epoch 113/300, Loss: 0.0005568259692599971, Test Accuracy: 46.94%\n",
            "Epoch 114/300, Loss: 0.0005492861648284581, Test Accuracy: 46.97%\n",
            "Epoch 115/300, Loss: 0.000543429875966538, Test Accuracy: 46.94%\n",
            "Epoch 116/300, Loss: 0.0005362293081103645, Test Accuracy: 46.89%\n",
            "Epoch 117/300, Loss: 0.0005299697547860685, Test Accuracy: 46.90%\n",
            "Epoch 118/300, Loss: 0.0005238195722507818, Test Accuracy: 46.88%\n",
            "Epoch 119/300, Loss: 0.0005171164206609157, Test Accuracy: 46.87%\n",
            "Epoch 120/300, Loss: 0.0005113317446227699, Test Accuracy: 46.95%\n",
            "Epoch 121/300, Loss: 0.0005046013384594619, Test Accuracy: 46.90%\n",
            "Epoch 122/300, Loss: 0.000499550687932047, Test Accuracy: 46.90%\n",
            "Epoch 123/300, Loss: 0.0004933644802825286, Test Accuracy: 46.88%\n",
            "Epoch 124/300, Loss: 0.00048782649078785953, Test Accuracy: 46.85%\n",
            "Epoch 125/300, Loss: 0.00048261001165272513, Test Accuracy: 46.99%\n",
            "Epoch 126/300, Loss: 0.00047694259308544014, Test Accuracy: 46.91%\n",
            "Epoch 127/300, Loss: 0.00047201027593958854, Test Accuracy: 46.88%\n",
            "Epoch 128/300, Loss: 0.0004671296689453638, Test Accuracy: 46.89%\n",
            "Epoch 129/300, Loss: 0.0004617527147897436, Test Accuracy: 46.84%\n",
            "Epoch 130/300, Loss: 0.0004569199096918838, Test Accuracy: 46.84%\n",
            "Epoch 131/300, Loss: 0.00045261666887138583, Test Accuracy: 46.90%\n",
            "Epoch 132/300, Loss: 0.0004472789728410139, Test Accuracy: 46.81%\n",
            "Epoch 133/300, Loss: 0.0004429514425650587, Test Accuracy: 46.87%\n",
            "Epoch 134/300, Loss: 0.00043802658504936355, Test Accuracy: 46.86%\n",
            "Epoch 135/300, Loss: 0.00043440473256672906, Test Accuracy: 46.94%\n",
            "Epoch 136/300, Loss: 0.0004297662727191111, Test Accuracy: 46.94%\n",
            "Epoch 137/300, Loss: 0.0004250964369777988, Test Accuracy: 46.86%\n",
            "Epoch 138/300, Loss: 0.0004211614611035753, Test Accuracy: 46.83%\n",
            "Epoch 139/300, Loss: 0.00041678889682097867, Test Accuracy: 46.85%\n",
            "Epoch 140/300, Loss: 0.0004132035766841137, Test Accuracy: 46.91%\n",
            "Epoch 141/300, Loss: 0.0004092731355702575, Test Accuracy: 46.89%\n",
            "Epoch 142/300, Loss: 0.00040516015181491616, Test Accuracy: 46.82%\n",
            "Epoch 143/300, Loss: 0.0004017996226073322, Test Accuracy: 46.84%\n",
            "Epoch 144/300, Loss: 0.00039749960538519157, Test Accuracy: 46.83%\n",
            "Epoch 145/300, Loss: 0.0003940718562539753, Test Accuracy: 46.84%\n",
            "Epoch 146/300, Loss: 0.0003907004806092569, Test Accuracy: 46.88%\n",
            "Epoch 147/300, Loss: 0.0003869580614403777, Test Accuracy: 46.90%\n",
            "Epoch 148/300, Loss: 0.0003834976134387543, Test Accuracy: 46.82%\n",
            "Epoch 149/300, Loss: 0.00038017650141266917, Test Accuracy: 46.86%\n",
            "Epoch 150/300, Loss: 0.0003767475790321238, Test Accuracy: 46.90%\n",
            "Epoch 151/300, Loss: 0.00037327555051767307, Test Accuracy: 46.89%\n",
            "Epoch 152/300, Loss: 0.000370033468197522, Test Accuracy: 46.87%\n",
            "Epoch 153/300, Loss: 0.00036694582821659045, Test Accuracy: 46.94%\n",
            "Epoch 154/300, Loss: 0.00036401658044228695, Test Accuracy: 46.82%\n",
            "Epoch 155/300, Loss: 0.00036085934460006555, Test Accuracy: 46.86%\n",
            "Epoch 156/300, Loss: 0.00035765083683951846, Test Accuracy: 46.84%\n",
            "Epoch 157/300, Loss: 0.000355032189668629, Test Accuracy: 46.78%\n",
            "Epoch 158/300, Loss: 0.00035191663477105947, Test Accuracy: 46.80%\n",
            "Epoch 159/300, Loss: 0.0003491253766268629, Test Accuracy: 46.83%\n",
            "Epoch 160/300, Loss: 0.0003462016289365214, Test Accuracy: 46.82%\n",
            "Epoch 161/300, Loss: 0.00034325698817794416, Test Accuracy: 46.86%\n",
            "Epoch 162/300, Loss: 0.00034051378390262285, Test Accuracy: 46.80%\n",
            "Epoch 163/300, Loss: 0.0003378253464724973, Test Accuracy: 46.78%\n",
            "Epoch 164/300, Loss: 0.00033542268694596223, Test Accuracy: 46.78%\n",
            "Epoch 165/300, Loss: 0.0003327017713494772, Test Accuracy: 46.81%\n",
            "Epoch 166/300, Loss: 0.00033000671864941275, Test Accuracy: 46.79%\n",
            "Epoch 167/300, Loss: 0.0003277048876909262, Test Accuracy: 46.82%\n",
            "Epoch 168/300, Loss: 0.0003247682562999735, Test Accuracy: 46.75%\n",
            "Epoch 169/300, Loss: 0.00032253424548274364, Test Accuracy: 46.78%\n",
            "Epoch 170/300, Loss: 0.0003199674153078695, Test Accuracy: 46.83%\n",
            "Epoch 171/300, Loss: 0.0003176965789419333, Test Accuracy: 46.80%\n",
            "Epoch 172/300, Loss: 0.0003153674822796052, Test Accuracy: 46.76%\n",
            "Epoch 173/300, Loss: 0.00031304674765703783, Test Accuracy: 46.82%\n",
            "Epoch 174/300, Loss: 0.000310618906720848, Test Accuracy: 46.79%\n",
            "Epoch 175/300, Loss: 0.00030835229948316317, Test Accuracy: 46.77%\n",
            "Epoch 176/300, Loss: 0.00030603263983096314, Test Accuracy: 46.78%\n",
            "Epoch 177/300, Loss: 0.00030396391171980645, Test Accuracy: 46.73%\n",
            "Epoch 178/300, Loss: 0.0003016887370210829, Test Accuracy: 46.85%\n",
            "Epoch 179/300, Loss: 0.0002992394439177364, Test Accuracy: 46.77%\n",
            "Epoch 180/300, Loss: 0.0002975537239517513, Test Accuracy: 46.76%\n",
            "Epoch 181/300, Loss: 0.00029533014010781154, Test Accuracy: 46.80%\n",
            "Epoch 182/300, Loss: 0.0002934888317391976, Test Accuracy: 46.81%\n",
            "Epoch 183/300, Loss: 0.0002914374784379289, Test Accuracy: 46.72%\n",
            "Epoch 184/300, Loss: 0.0002893308911079518, Test Accuracy: 46.72%\n",
            "Epoch 185/300, Loss: 0.0002872379253202735, Test Accuracy: 46.80%\n",
            "Epoch 186/300, Loss: 0.000285293885215614, Test Accuracy: 46.81%\n",
            "Epoch 187/300, Loss: 0.0002833980410076396, Test Accuracy: 46.75%\n",
            "Epoch 188/300, Loss: 0.0002816507916244552, Test Accuracy: 46.75%\n",
            "Epoch 189/300, Loss: 0.00027974110435083257, Test Accuracy: 46.76%\n",
            "Epoch 190/300, Loss: 0.0002777787731544136, Test Accuracy: 46.76%\n",
            "Epoch 191/300, Loss: 0.0002759218993571409, Test Accuracy: 46.76%\n",
            "Epoch 192/300, Loss: 0.0002742281998070097, Test Accuracy: 46.79%\n",
            "Epoch 193/300, Loss: 0.0002722777444165053, Test Accuracy: 46.74%\n",
            "Epoch 194/300, Loss: 0.00027068899680292936, Test Accuracy: 46.76%\n",
            "Epoch 195/300, Loss: 0.00026898530344338014, Test Accuracy: 46.74%\n",
            "Epoch 196/300, Loss: 0.0002672253021973296, Test Accuracy: 46.76%\n",
            "Epoch 197/300, Loss: 0.0002655841584345466, Test Accuracy: 46.76%\n",
            "Epoch 198/300, Loss: 0.0002640276948686913, Test Accuracy: 46.74%\n",
            "Epoch 199/300, Loss: 0.0002622142035334391, Test Accuracy: 46.71%\n",
            "Epoch 200/300, Loss: 0.0002602529764344936, Test Accuracy: 46.72%\n",
            "Epoch 201/300, Loss: 0.0002590156764967587, Test Accuracy: 46.74%\n",
            "Epoch 202/300, Loss: 0.0002572852644708645, Test Accuracy: 46.75%\n",
            "Epoch 203/300, Loss: 0.00025568007957990955, Test Accuracy: 46.70%\n",
            "Epoch 204/300, Loss: 0.0002540370748292012, Test Accuracy: 46.69%\n",
            "Epoch 205/300, Loss: 0.0002525416801073076, Test Accuracy: 46.70%\n",
            "Epoch 206/300, Loss: 0.00025122583301836815, Test Accuracy: 46.72%\n",
            "Epoch 207/300, Loss: 0.0002495780431501098, Test Accuracy: 46.68%\n",
            "Epoch 208/300, Loss: 0.0002481935677998306, Test Accuracy: 46.73%\n",
            "Epoch 209/300, Loss: 0.0002466378266904807, Test Accuracy: 46.72%\n",
            "Epoch 210/300, Loss: 0.0002451665362246217, Test Accuracy: 46.71%\n",
            "Epoch 211/300, Loss: 0.00024364997881906486, Test Accuracy: 46.75%\n",
            "Epoch 212/300, Loss: 0.00024233620813387844, Test Accuracy: 46.71%\n",
            "Epoch 213/300, Loss: 0.0002409341977862656, Test Accuracy: 46.63%\n",
            "Epoch 214/300, Loss: 0.00023955898838430096, Test Accuracy: 46.70%\n",
            "Epoch 215/300, Loss: 0.0002382216983220733, Test Accuracy: 46.66%\n",
            "Epoch 216/300, Loss: 0.00023680859218099497, Test Accuracy: 46.69%\n",
            "Epoch 217/300, Loss: 0.00023545855829529898, Test Accuracy: 46.69%\n",
            "Epoch 218/300, Loss: 0.00023404534902927564, Test Accuracy: 46.70%\n",
            "Epoch 219/300, Loss: 0.00023273654160855018, Test Accuracy: 46.74%\n",
            "Epoch 220/300, Loss: 0.00023154051414935137, Test Accuracy: 46.73%\n",
            "Epoch 221/300, Loss: 0.0002301924959017573, Test Accuracy: 46.74%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FlMvUXiCvg4q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}